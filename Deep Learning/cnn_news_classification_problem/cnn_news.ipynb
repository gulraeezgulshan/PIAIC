{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Any results you write to the current directory are saved as output.\n",
    "import itertools\n",
    "\n",
    "# %matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from tensorflow import keras\n",
    "layers = keras.layers\n",
    "models = keras.models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"bbc-text.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tech</td>\n",
       "      <td>tv future in the hands of viewers with home th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>worldcom boss  left books alone  former worldc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sport</td>\n",
       "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sport</td>\n",
       "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>politics</td>\n",
       "      <td>howard hits back at mongrel jibe michael howar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>politics</td>\n",
       "      <td>blair prepares to name poll date tony blair is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sport</td>\n",
       "      <td>henman hopes ended in dubai third seed tim hen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sport</td>\n",
       "      <td>wilkinson fit to face edinburgh england captai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>last star wars  not for children  the sixth an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>berlin cheers for anti-nazi film a german movi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>business</td>\n",
       "      <td>virgin blue shares plummet 20% shares in austr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>business</td>\n",
       "      <td>crude oil prices back above $50 cold weather a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>politics</td>\n",
       "      <td>hague  given up  his pm ambition former conser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sport</td>\n",
       "      <td>moya emotional after davis cup win carlos moya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>business</td>\n",
       "      <td>s korean credit card firm rescued south korea ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>politics</td>\n",
       "      <td>howard backs stem cell research michael howard...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>sport</td>\n",
       "      <td>connors boost for british tennis former world ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>business</td>\n",
       "      <td>japanese banking battle at an end japan s sumi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>tech</td>\n",
       "      <td>games maker fights for survival one of britain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>tech</td>\n",
       "      <td>security warning over  fbi virus  the us feder...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>tech</td>\n",
       "      <td>halo 2 heralds traffic explosion the growing p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>sport</td>\n",
       "      <td>bates seals takeover ken bates has completed h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>sport</td>\n",
       "      <td>cole faces lengthy injury lay-off aston villa ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>tech</td>\n",
       "      <td>mobile audio enters new dimension as mobile ph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>sport</td>\n",
       "      <td>moya fights back for indian title carlos moya ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>career honour for actor dicaprio actor leonard...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>tech</td>\n",
       "      <td>mobile gig aims to rock 3g forget about going ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>politics</td>\n",
       "      <td>terror suspects face house arrest uk citizens ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>halloween writer debra hill dies screenwriter ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>sport</td>\n",
       "      <td>owen delighted with real display michael owen ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>business</td>\n",
       "      <td>gm issues 2005 profits warning general motors ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2197</th>\n",
       "      <td>politics</td>\n",
       "      <td>campbell returns to election team ex-downing s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2198</th>\n",
       "      <td>business</td>\n",
       "      <td>asian banks halt dollar s slide the dollar reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2199</th>\n",
       "      <td>business</td>\n",
       "      <td>wall street cool to ebay s profit shares in on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2200</th>\n",
       "      <td>tech</td>\n",
       "      <td>uk pioneers digital film network the world s f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2201</th>\n",
       "      <td>business</td>\n",
       "      <td>ban on forced retirement under 65 employers wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2202</th>\n",
       "      <td>tech</td>\n",
       "      <td>local net tv takes off in austria an austrian ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2203</th>\n",
       "      <td>politics</td>\n",
       "      <td>profile: david miliband david miliband s rapid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2204</th>\n",
       "      <td>tech</td>\n",
       "      <td>argonaut founder rebuilds empire jez san  the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2205</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>dance music not dead says fatboy dj norman coo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2206</th>\n",
       "      <td>politics</td>\n",
       "      <td>kennedy questions trust of blair lib dem leade...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2207</th>\n",
       "      <td>tech</td>\n",
       "      <td>california sets fines for spyware the makers o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2208</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>snicket tops us box office chart the film adap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2209</th>\n",
       "      <td>sport</td>\n",
       "      <td>time to get tough on friendlies  for an intern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2210</th>\n",
       "      <td>politics</td>\n",
       "      <td>teens  know little  of politics teenagers ques...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2211</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>lopez misses uk charity premiere jennifer lope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2212</th>\n",
       "      <td>business</td>\n",
       "      <td>christmas shoppers flock to tills shops all ov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2213</th>\n",
       "      <td>tech</td>\n",
       "      <td>progress on new internet domains by early 2005...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2214</th>\n",
       "      <td>business</td>\n",
       "      <td>bush budget seeks deep cutbacks president bush...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2215</th>\n",
       "      <td>tech</td>\n",
       "      <td>junk e-mails on relentless rise spam traffic i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2216</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>top stars join us tsunami tv show brad pitt  r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2217</th>\n",
       "      <td>tech</td>\n",
       "      <td>rings of steel combat net attacks gambling is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2218</th>\n",
       "      <td>sport</td>\n",
       "      <td>davies favours gloucester future wales hooker ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2219</th>\n",
       "      <td>business</td>\n",
       "      <td>beijingers fume over parking fees choking traf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>business</td>\n",
       "      <td>cars pull down us retail figures us retail sal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>politics</td>\n",
       "      <td>kilroy unveils immigration policy ex-chatshow ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>rem announce new glasgow concert us band rem h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>politics</td>\n",
       "      <td>how political squabbles snowball it s become c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>sport</td>\n",
       "      <td>souness delight at euro progress boss graeme s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2225 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           category                                               text\n",
       "0              tech  tv future in the hands of viewers with home th...\n",
       "1          business  worldcom boss  left books alone  former worldc...\n",
       "2             sport  tigers wary of farrell  gamble  leicester say ...\n",
       "3             sport  yeading face newcastle in fa cup premiership s...\n",
       "4     entertainment  ocean s twelve raids box office ocean s twelve...\n",
       "5          politics  howard hits back at mongrel jibe michael howar...\n",
       "6          politics  blair prepares to name poll date tony blair is...\n",
       "7             sport  henman hopes ended in dubai third seed tim hen...\n",
       "8             sport  wilkinson fit to face edinburgh england captai...\n",
       "9     entertainment  last star wars  not for children  the sixth an...\n",
       "10    entertainment  berlin cheers for anti-nazi film a german movi...\n",
       "11         business  virgin blue shares plummet 20% shares in austr...\n",
       "12         business  crude oil prices back above $50 cold weather a...\n",
       "13         politics  hague  given up  his pm ambition former conser...\n",
       "14            sport  moya emotional after davis cup win carlos moya...\n",
       "15         business  s korean credit card firm rescued south korea ...\n",
       "16         politics  howard backs stem cell research michael howard...\n",
       "17            sport  connors boost for british tennis former world ...\n",
       "18         business  japanese banking battle at an end japan s sumi...\n",
       "19             tech  games maker fights for survival one of britain...\n",
       "20             tech  security warning over  fbi virus  the us feder...\n",
       "21             tech  halo 2 heralds traffic explosion the growing p...\n",
       "22            sport  bates seals takeover ken bates has completed h...\n",
       "23            sport  cole faces lengthy injury lay-off aston villa ...\n",
       "24             tech  mobile audio enters new dimension as mobile ph...\n",
       "25            sport  moya fights back for indian title carlos moya ...\n",
       "26    entertainment  career honour for actor dicaprio actor leonard...\n",
       "27             tech  mobile gig aims to rock 3g forget about going ...\n",
       "28         politics  terror suspects face house arrest uk citizens ...\n",
       "29    entertainment  halloween writer debra hill dies screenwriter ...\n",
       "...             ...                                                ...\n",
       "2195          sport  owen delighted with real display michael owen ...\n",
       "2196       business  gm issues 2005 profits warning general motors ...\n",
       "2197       politics  campbell returns to election team ex-downing s...\n",
       "2198       business  asian banks halt dollar s slide the dollar reg...\n",
       "2199       business  wall street cool to ebay s profit shares in on...\n",
       "2200           tech  uk pioneers digital film network the world s f...\n",
       "2201       business  ban on forced retirement under 65 employers wi...\n",
       "2202           tech  local net tv takes off in austria an austrian ...\n",
       "2203       politics  profile: david miliband david miliband s rapid...\n",
       "2204           tech  argonaut founder rebuilds empire jez san  the ...\n",
       "2205  entertainment  dance music not dead says fatboy dj norman coo...\n",
       "2206       politics  kennedy questions trust of blair lib dem leade...\n",
       "2207           tech  california sets fines for spyware the makers o...\n",
       "2208  entertainment  snicket tops us box office chart the film adap...\n",
       "2209          sport  time to get tough on friendlies  for an intern...\n",
       "2210       politics  teens  know little  of politics teenagers ques...\n",
       "2211  entertainment  lopez misses uk charity premiere jennifer lope...\n",
       "2212       business  christmas shoppers flock to tills shops all ov...\n",
       "2213           tech  progress on new internet domains by early 2005...\n",
       "2214       business  bush budget seeks deep cutbacks president bush...\n",
       "2215           tech  junk e-mails on relentless rise spam traffic i...\n",
       "2216  entertainment  top stars join us tsunami tv show brad pitt  r...\n",
       "2217           tech  rings of steel combat net attacks gambling is ...\n",
       "2218          sport  davies favours gloucester future wales hooker ...\n",
       "2219       business  beijingers fume over parking fees choking traf...\n",
       "2220       business  cars pull down us retail figures us retail sal...\n",
       "2221       politics  kilroy unveils immigration policy ex-chatshow ...\n",
       "2222  entertainment  rem announce new glasgow concert us band rem h...\n",
       "2223       politics  how political squabbles snowball it s become c...\n",
       "2224          sport  souness delight at euro progress boss graeme s...\n",
       "\n",
       "[2225 rows x 2 columns]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2225, 2)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tech</td>\n",
       "      <td>tv future in the hands of viewers with home th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>worldcom boss  left books alone  former worldc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sport</td>\n",
       "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sport</td>\n",
       "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                               text\n",
       "0           tech  tv future in the hands of viewers with home th...\n",
       "1       business  worldcom boss  left books alone  former worldc...\n",
       "2          sport  tigers wary of farrell  gamble  leicester say ...\n",
       "3          sport  yeading face newcastle in fa cup premiership s...\n",
       "4  entertainment  ocean s twelve raids box office ocean s twelve..."
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sport            511\n",
       "business         510\n",
       "politics         417\n",
       "tech             401\n",
       "entertainment    386\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 1780\n",
      "Test size: 445\n"
     ]
    }
   ],
   "source": [
    "train_size = int(len(data) * .8)\n",
    "print (\"Train size: %d\" % train_size)\n",
    "print (\"Test size: %d\" % (len(data) - train_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(data, train_size):\n",
    "    train = data[:train_size]\n",
    "    test = data[train_size:]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cat, test_cat = train_test_split(data['category'], train_size)\n",
    "train_text, test_text = train_test_split(data['text'], train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                tech\n",
       "1            business\n",
       "2               sport\n",
       "3               sport\n",
       "4       entertainment\n",
       "5            politics\n",
       "6            politics\n",
       "7               sport\n",
       "8               sport\n",
       "9       entertainment\n",
       "10      entertainment\n",
       "11           business\n",
       "12           business\n",
       "13           politics\n",
       "14              sport\n",
       "15           business\n",
       "16           politics\n",
       "17              sport\n",
       "18           business\n",
       "19               tech\n",
       "20               tech\n",
       "21               tech\n",
       "22              sport\n",
       "23              sport\n",
       "24               tech\n",
       "25              sport\n",
       "26      entertainment\n",
       "27               tech\n",
       "28           politics\n",
       "29      entertainment\n",
       "            ...      \n",
       "1750            sport\n",
       "1751    entertainment\n",
       "1752    entertainment\n",
       "1753         business\n",
       "1754             tech\n",
       "1755             tech\n",
       "1756         business\n",
       "1757             tech\n",
       "1758         business\n",
       "1759         business\n",
       "1760            sport\n",
       "1761            sport\n",
       "1762         politics\n",
       "1763            sport\n",
       "1764             tech\n",
       "1765            sport\n",
       "1766             tech\n",
       "1767            sport\n",
       "1768            sport\n",
       "1769         business\n",
       "1770         business\n",
       "1771             tech\n",
       "1772            sport\n",
       "1773         business\n",
       "1774             tech\n",
       "1775             tech\n",
       "1776         politics\n",
       "1777            sport\n",
       "1778         business\n",
       "1779    entertainment\n",
       "Name: category, Length: 1780, dtype: object"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1780    entertainment\n",
       "1781             tech\n",
       "1782         politics\n",
       "1783            sport\n",
       "1784            sport\n",
       "1785             tech\n",
       "1786         business\n",
       "1787             tech\n",
       "1788    entertainment\n",
       "1789    entertainment\n",
       "1790         politics\n",
       "1791         politics\n",
       "1792         business\n",
       "1793    entertainment\n",
       "1794            sport\n",
       "1795    entertainment\n",
       "1796    entertainment\n",
       "1797         business\n",
       "1798            sport\n",
       "1799         politics\n",
       "1800             tech\n",
       "1801         business\n",
       "1802            sport\n",
       "1803    entertainment\n",
       "1804             tech\n",
       "1805         politics\n",
       "1806         politics\n",
       "1807            sport\n",
       "1808            sport\n",
       "1809         business\n",
       "            ...      \n",
       "2195            sport\n",
       "2196         business\n",
       "2197         politics\n",
       "2198         business\n",
       "2199         business\n",
       "2200             tech\n",
       "2201         business\n",
       "2202             tech\n",
       "2203         politics\n",
       "2204             tech\n",
       "2205    entertainment\n",
       "2206         politics\n",
       "2207             tech\n",
       "2208    entertainment\n",
       "2209            sport\n",
       "2210         politics\n",
       "2211    entertainment\n",
       "2212         business\n",
       "2213             tech\n",
       "2214         business\n",
       "2215             tech\n",
       "2216    entertainment\n",
       "2217             tech\n",
       "2218            sport\n",
       "2219         business\n",
       "2220         business\n",
       "2221         politics\n",
       "2222    entertainment\n",
       "2223         politics\n",
       "2224            sport\n",
       "Name: category, Length: 445, dtype: object"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       tv future in the hands of viewers with home th...\n",
       "1       worldcom boss  left books alone  former worldc...\n",
       "2       tigers wary of farrell  gamble  leicester say ...\n",
       "3       yeading face newcastle in fa cup premiership s...\n",
       "4       ocean s twelve raids box office ocean s twelve...\n",
       "5       howard hits back at mongrel jibe michael howar...\n",
       "6       blair prepares to name poll date tony blair is...\n",
       "7       henman hopes ended in dubai third seed tim hen...\n",
       "8       wilkinson fit to face edinburgh england captai...\n",
       "9       last star wars  not for children  the sixth an...\n",
       "10      berlin cheers for anti-nazi film a german movi...\n",
       "11      virgin blue shares plummet 20% shares in austr...\n",
       "12      crude oil prices back above $50 cold weather a...\n",
       "13      hague  given up  his pm ambition former conser...\n",
       "14      moya emotional after davis cup win carlos moya...\n",
       "15      s korean credit card firm rescued south korea ...\n",
       "16      howard backs stem cell research michael howard...\n",
       "17      connors boost for british tennis former world ...\n",
       "18      japanese banking battle at an end japan s sumi...\n",
       "19      games maker fights for survival one of britain...\n",
       "20      security warning over  fbi virus  the us feder...\n",
       "21      halo 2 heralds traffic explosion the growing p...\n",
       "22      bates seals takeover ken bates has completed h...\n",
       "23      cole faces lengthy injury lay-off aston villa ...\n",
       "24      mobile audio enters new dimension as mobile ph...\n",
       "25      moya fights back for indian title carlos moya ...\n",
       "26      career honour for actor dicaprio actor leonard...\n",
       "27      mobile gig aims to rock 3g forget about going ...\n",
       "28      terror suspects face house arrest uk citizens ...\n",
       "29      halloween writer debra hill dies screenwriter ...\n",
       "                              ...                        \n",
       "1750    connors  rallying cry for british tennis  do y...\n",
       "1751    foxx and swank win us awards jamie foxx and hi...\n",
       "1752    abba reunite for musical premiere the original...\n",
       "1753    wembley firm won t make a profit shares in mul...\n",
       "1754    home phones face unclear future the fixed line...\n",
       "1755    2d metal slug offers retro fun like some drill...\n",
       "1756    laura ashley chief stepping down laura ashley ...\n",
       "1757    nuclear body seeks new tech the computer syste...\n",
       "1758    india s deccan seals $1.8bn deal air deccan ha...\n",
       "1759    jarvis sells tube stake to spain shares in eng...\n",
       "1760    mcclaren hails boro s uefa spirit middlesbroug...\n",
       "1761    campese berates whingeing england former austr...\n",
       "1762    mps quiz aides over royal income senior offici...\n",
       "1763    mourinho to escape fa charge chelsea boss jose...\n",
       "1764    nintendo ds aims to touch gamers the mobile ga...\n",
       "1765    vickery upbeat about arm injury england prop p...\n",
       "1766    china  to overtake us net use  the chinese net...\n",
       "1767    downing injury mars uefa victory middlesbrough...\n",
       "1768    curbishley delight for johansson charlton mana...\n",
       "1769    eu ministers to mull jet fuel tax european uni...\n",
       "1770    astrazeneca hit by drug failure shares in angl...\n",
       "1771    apple laptop is  greatest gadget  the apple po...\n",
       "1772    athens memories soar above lows well  it s goo...\n",
       "1773    hyundai to build new india plant south korea s...\n",
       "1774    warning over tsunami aid website net users are...\n",
       "1775    china  blocks google news site  china has been...\n",
       "1776    labour accused of  eu propaganda  a  taxpayer ...\n",
       "1777    tevez - an argentine in brazil some 65 years a...\n",
       "1778    water firm suez in argentina row a conflict be...\n",
       "1779    tv presenter deeley drops cd:uk cat deeley has...\n",
       "Name: text, Length: 1780, dtype: object"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1780    hobbit picture  four years away  lord of the r...\n",
       "1781    game firm holds  cast  auditions video game fi...\n",
       "1782    clarke plans migrant point scheme anyone plann...\n",
       "1783    radcliffe will compete in london paula radclif...\n",
       "1784    serena becomes world number two serena william...\n",
       "1785    ultimate game  award for doom 3 sci-fi shooter...\n",
       "1786    algeria hit by further gas riots algeria suffe...\n",
       "1787    fast lifts rise into record books two high-spe...\n",
       "1788    muslim group attacks tv drama 24 a british mus...\n",
       "1789    us tv special for tsunami relief a us televisi...\n",
       "1790    brown names 16 march for budget chancellor gor...\n",
       "1791    choose hope over fear - kennedy voters will ha...\n",
       "1792    worldcom bosses  $54m payout ten former direct...\n",
       "1793    de niro film leads us box office film star rob...\n",
       "1794    robinson ready for difficult task england coac...\n",
       "1795    us tv cuts nudity from bbc film a us tv networ...\n",
       "1796    french honour for director parker british film...\n",
       "1797    standoff  on deutsche s lse bid deutsche boers...\n",
       "1798    chepkemei hit by big ban kenya s athletics bod...\n",
       "1799    peace demo appeal rejected peace protestors ha...\n",
       "1800    microsoft makes anti-piracy move microsoft say...\n",
       "1801    continental  may run out of cash  shares in co...\n",
       "1802    souness eyes summer move for owen newcastle bo...\n",
       "1803    super size me wins writers  award super size m...\n",
       "1804    dublin hi-tech labs to shut down dublin s hi-t...\n",
       "1805    kelly trails new discipline power teachers cou...\n",
       "1806    clarke to unveil immigration plan new controls...\n",
       "1807    english clubs make euro history all four of en...\n",
       "1808    dal maso in to replace bergamasco david dal ma...\n",
       "1809    golden rule  intact  says ex-aide chancellor g...\n",
       "                              ...                        \n",
       "2195    owen delighted with real display michael owen ...\n",
       "2196    gm issues 2005 profits warning general motors ...\n",
       "2197    campbell returns to election team ex-downing s...\n",
       "2198    asian banks halt dollar s slide the dollar reg...\n",
       "2199    wall street cool to ebay s profit shares in on...\n",
       "2200    uk pioneers digital film network the world s f...\n",
       "2201    ban on forced retirement under 65 employers wi...\n",
       "2202    local net tv takes off in austria an austrian ...\n",
       "2203    profile: david miliband david miliband s rapid...\n",
       "2204    argonaut founder rebuilds empire jez san  the ...\n",
       "2205    dance music not dead says fatboy dj norman coo...\n",
       "2206    kennedy questions trust of blair lib dem leade...\n",
       "2207    california sets fines for spyware the makers o...\n",
       "2208    snicket tops us box office chart the film adap...\n",
       "2209    time to get tough on friendlies  for an intern...\n",
       "2210    teens  know little  of politics teenagers ques...\n",
       "2211    lopez misses uk charity premiere jennifer lope...\n",
       "2212    christmas shoppers flock to tills shops all ov...\n",
       "2213    progress on new internet domains by early 2005...\n",
       "2214    bush budget seeks deep cutbacks president bush...\n",
       "2215    junk e-mails on relentless rise spam traffic i...\n",
       "2216    top stars join us tsunami tv show brad pitt  r...\n",
       "2217    rings of steel combat net attacks gambling is ...\n",
       "2218    davies favours gloucester future wales hooker ...\n",
       "2219    beijingers fume over parking fees choking traf...\n",
       "2220    cars pull down us retail figures us retail sal...\n",
       "2221    kilroy unveils immigration policy ex-chatshow ...\n",
       "2222    rem announce new glasgow concert us band rem h...\n",
       "2223    how political squabbles snowball it s become c...\n",
       "2224    souness delight at euro progress boss graeme s...\n",
       "Name: text, Length: 445, dtype: object"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer\n",
    "\n",
    "Class for vectorizing texts, or/and turning texts into sequences (=list of word indexes, where the word of rank i in the dataset (starting at 1) has index i).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3, 4, 5]]\n",
      "[[1, 2, 3, 5]]\n",
      "[[0. 1. 1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "#example for tokenizer\n",
    "#zero index is reserved for padding\n",
    "#Tokenize meaning : break (text) into individual linguistic units.\n",
    "#zero in matrix is reserved for Embedding Layer\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "tok = Tokenizer()\n",
    "#tok = Tokenizer(num_words=10, char_level=False)\n",
    "tok.fit_on_texts([\"this comment is not toxic\"]) \n",
    "print(tok.texts_to_sequences([\"this comment is not toxic\"])) \n",
    "print(tok.texts_to_sequences([\"this very long comment is  toxic\"]))\n",
    "print(tok.texts_to_matrix([\"this comment is not toxic\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 1000\n",
    "tokenize = keras.preprocessing.text.Tokenizer(num_words=max_words, char_level=False)\n",
    "#tokenize = keras.preprocessing.text.Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize.fit_on_texts(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tokenize.texts_to_matrix(train_text)\n",
    "x_test = tokenize.texts_to_matrix(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 1., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1.,\n",
       "       0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1.,\n",
       "       0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1.,\n",
       "       1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1.,\n",
       "       1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1.,\n",
       "       1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train[0]))\n",
    "print(len(x_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1780, 1000)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(445, 1000)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                tech\n",
       "1            business\n",
       "2               sport\n",
       "3               sport\n",
       "4       entertainment\n",
       "5            politics\n",
       "6            politics\n",
       "7               sport\n",
       "8               sport\n",
       "9       entertainment\n",
       "10      entertainment\n",
       "11           business\n",
       "12           business\n",
       "13           politics\n",
       "14              sport\n",
       "15           business\n",
       "16           politics\n",
       "17              sport\n",
       "18           business\n",
       "19               tech\n",
       "20               tech\n",
       "21               tech\n",
       "22              sport\n",
       "23              sport\n",
       "24               tech\n",
       "25              sport\n",
       "26      entertainment\n",
       "27               tech\n",
       "28           politics\n",
       "29      entertainment\n",
       "            ...      \n",
       "1750            sport\n",
       "1751    entertainment\n",
       "1752    entertainment\n",
       "1753         business\n",
       "1754             tech\n",
       "1755             tech\n",
       "1756         business\n",
       "1757             tech\n",
       "1758         business\n",
       "1759         business\n",
       "1760            sport\n",
       "1761            sport\n",
       "1762         politics\n",
       "1763            sport\n",
       "1764             tech\n",
       "1765            sport\n",
       "1766             tech\n",
       "1767            sport\n",
       "1768            sport\n",
       "1769         business\n",
       "1770         business\n",
       "1771             tech\n",
       "1772            sport\n",
       "1773         business\n",
       "1774             tech\n",
       "1775             tech\n",
       "1776         politics\n",
       "1777            sport\n",
       "1778         business\n",
       "1779    entertainment\n",
       "Name: category, Length: 1780, dtype: object"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1780    entertainment\n",
       "1781             tech\n",
       "1782         politics\n",
       "1783            sport\n",
       "1784            sport\n",
       "1785             tech\n",
       "1786         business\n",
       "1787             tech\n",
       "1788    entertainment\n",
       "1789    entertainment\n",
       "1790         politics\n",
       "1791         politics\n",
       "1792         business\n",
       "1793    entertainment\n",
       "1794            sport\n",
       "1795    entertainment\n",
       "1796    entertainment\n",
       "1797         business\n",
       "1798            sport\n",
       "1799         politics\n",
       "1800             tech\n",
       "1801         business\n",
       "1802            sport\n",
       "1803    entertainment\n",
       "1804             tech\n",
       "1805         politics\n",
       "1806         politics\n",
       "1807            sport\n",
       "1808            sport\n",
       "1809         business\n",
       "            ...      \n",
       "2195            sport\n",
       "2196         business\n",
       "2197         politics\n",
       "2198         business\n",
       "2199         business\n",
       "2200             tech\n",
       "2201         business\n",
       "2202             tech\n",
       "2203         politics\n",
       "2204             tech\n",
       "2205    entertainment\n",
       "2206         politics\n",
       "2207             tech\n",
       "2208    entertainment\n",
       "2209            sport\n",
       "2210         politics\n",
       "2211    entertainment\n",
       "2212         business\n",
       "2213             tech\n",
       "2214         business\n",
       "2215             tech\n",
       "2216    entertainment\n",
       "2217             tech\n",
       "2218            sport\n",
       "2219         business\n",
       "2220         business\n",
       "2221         politics\n",
       "2222    entertainment\n",
       "2223         politics\n",
       "2224            sport\n",
       "Name: category, Length: 445, dtype: object"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Understanding encoder\n",
    "\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['amsterdam', 'paris', 'tokyo']"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.fit([\"paris\", \"paris\", \"tokyo\", \"amsterdam\"])\n",
    "list(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['tokyo', 'tokyo', 'paris']"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(le.transform([\"amsterdam\", \"tokyo\", \"paris\"]))\n",
    "list(le.inverse_transform([2, 2, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(train_cat)\n",
    "y_train = encoder.transform(train_cat)\n",
    "y_test = encoder.transform(test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0, 3, ..., 3, 0, 1])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1780"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 4, 2, 3, 3, 4, 0, 4, 1, 1, 2, 2, 0, 1, 3, 1, 1, 0, 3, 2, 4, 0,\n",
       "       3, 1, 4, 2, 2, 3, 3, 0, 0, 0, 0, 0, 1, 0, 2, 2, 4, 4, 1, 2, 1, 0,\n",
       "       2, 3, 3, 0, 4, 0, 4, 3, 0, 0, 2, 3, 3, 2, 2, 1, 1, 2, 0, 2, 2, 0,\n",
       "       4, 2, 2, 2, 2, 2, 1, 1, 4, 2, 3, 2, 3, 4, 3, 3, 3, 1, 4, 1, 4, 3,\n",
       "       4, 3, 3, 1, 1, 0, 1, 1, 2, 0, 3, 4, 4, 2, 0, 3, 0, 1, 3, 2, 1, 3,\n",
       "       3, 0, 2, 4, 4, 0, 0, 3, 2, 1, 3, 3, 2, 1, 4, 3, 1, 0, 2, 3, 2, 4,\n",
       "       1, 3, 2, 0, 1, 2, 1, 2, 3, 2, 0, 0, 2, 0, 4, 3, 0, 1, 0, 3, 3, 1,\n",
       "       4, 2, 4, 2, 2, 3, 3, 3, 0, 4, 1, 0, 3, 0, 3, 0, 4, 0, 0, 0, 0, 3,\n",
       "       3, 3, 0, 0, 1, 0, 0, 0, 3, 3, 3, 4, 0, 3, 3, 3, 0, 1, 4, 4, 4, 2,\n",
       "       0, 0, 4, 0, 4, 3, 3, 2, 2, 2, 3, 3, 2, 2, 4, 0, 3, 3, 3, 3, 0, 3,\n",
       "       0, 0, 0, 0, 3, 2, 3, 4, 4, 3, 4, 0, 1, 0, 3, 0, 4, 4, 2, 1, 0, 1,\n",
       "       0, 4, 2, 1, 2, 1, 1, 4, 0, 4, 4, 0, 2, 3, 1, 0, 2, 1, 0, 4, 3, 4,\n",
       "       2, 3, 2, 0, 2, 2, 0, 0, 0, 4, 2, 0, 2, 0, 1, 2, 3, 2, 2, 3, 1, 4,\n",
       "       4, 0, 4, 3, 0, 0, 2, 3, 4, 4, 4, 3, 1, 3, 2, 0, 2, 2, 1, 4, 0, 4,\n",
       "       3, 1, 1, 3, 0, 1, 4, 4, 3, 1, 0, 2, 2, 2, 4, 4, 0, 2, 0, 2, 2, 1,\n",
       "       3, 4, 0, 4, 1, 4, 4, 3, 2, 3, 3, 2, 1, 1, 0, 2, 2, 3, 0, 0, 4, 0,\n",
       "       4, 4, 3, 0, 2, 3, 0, 0, 3, 4, 3, 4, 1, 3, 3, 1, 0, 4, 3, 3, 2, 4,\n",
       "       0, 2, 3, 3, 2, 1, 4, 4, 4, 0, 3, 1, 1, 4, 0, 2, 4, 3, 3, 4, 4, 2,\n",
       "       0, 3, 1, 1, 3, 1, 4, 4, 0, 0, 0, 3, 3, 4, 3, 0, 4, 0, 0, 3, 0, 2,\n",
       "       0, 0, 4, 0, 4, 2, 4, 1, 2, 4, 1, 3, 2, 1, 0, 4, 0, 4, 1, 4, 3, 0,\n",
       "       0, 2, 1, 2, 3])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1780"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = np.max(y_train) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Consider an array of 5 labels out of a set of 3 classes {0, 1, 2}:\n",
    "labels = np.array([0, 2, 1, 2, 0])\n",
    "# `to_categorical` converts this into a matrix with as many\n",
    "# columns as there are classes. The number of rows\n",
    "# stays the same.\n",
    "keras.utils.to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts the labels to a one-hot representation\n",
    "num_classes = np.max(y_train) + 1\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 4\n",
    "drop_ratio = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(512, input_shape=(max_words,)))\n",
    "model.add(layers.Dense(212 , activation = 'relu'))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.Dense(num_classes))\n",
    "model.add(layers.Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 1., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1602 samples, validate on 178 samples\n",
      "Epoch 1/4\n",
      "1602/1602 [==============================] - 0s 258us/sample - loss: 0.3461 - acc: 0.8989 - val_loss: 0.1799 - val_acc: 0.9326\n",
      "Epoch 2/4\n",
      "1602/1602 [==============================] - 0s 175us/sample - loss: 0.0281 - acc: 0.9944 - val_loss: 0.1255 - val_acc: 0.9438\n",
      "Epoch 3/4\n",
      "1602/1602 [==============================] - 0s 174us/sample - loss: 0.0034 - acc: 1.0000 - val_loss: 0.1261 - val_acc: 0.9494\n",
      "Epoch 4/4\n",
      "1602/1602 [==============================] - 0s 176us/sample - loss: 0.0014 - acc: 1.0000 - val_loss: 0.1245 - val_acc: 0.9551\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,batch_size=batch_size,epochs=epochs,verbose=1,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "445/445 [==============================] - 0s 76us/sample - loss: 0.1587 - acc: 0.9573\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test,batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.15873410139191016\n",
      "Test accuracy: 0.95730335\n"
     ]
    }
   ],
   "source": [
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.predict(x_train[0])\n",
    "#x_train[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tunning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a good time to go back and tweak some parameters such as epoch, batch size, dropout ratio, network structure, activation function, and others, to see if you can improve the accuracy.\n",
    "\n",
    "In this particular case, to make it more challenging, I recommend reducing the max words of the call to keras.preprocessing.text.Tokenizer. This will reduce the number of words for each input sample, thus making it more challenging to accurately predict the category. (Notice that not all hyperparameters are necessarily inside the model. This is one such example.)\n",
    "\n",
    "The default was up to 1000 words per article. See what happens when you reduce that number to 200 words, or 50 words, or even fewer. As the evaluation accuracy drops, the effects of your hyperparameter tuning will be more pronounced, with successful adjustments making meaningful improvements to the model performance.\n",
    "\n",
    "To make this process easier to manage, I've encapulated the model definition and training and evaluation calls into one function call. You can add additional parameters as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#by using hyperprameter tunning\n",
    "\n",
    "def run_experiment(batch_size, epochs, drop_ratio):\n",
    "    print('batch size: {}, epochs: {}, drop_ratio: {}'.format(batch_size, epochs, drop_ratio))\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(512, input_shape=(max_words,)))\n",
    "    model.add(layers.Activation('relu'))\n",
    "    model.add(layers.Dropout(drop_ratio))\n",
    "    model.add(layers.Dense(num_classes))\n",
    "    model.add(layers.Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=0,\n",
    "                    validation_split=0.1)\n",
    "    score = model.evaluate(x_test, y_test,\n",
    "                       batch_size=batch_size, verbose=0)\n",
    "    print('\\tTest loss:', score[0])\n",
    "    print('\\tTest accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "epochs = 4\n",
    "drop_ratio = 0.4\n",
    "run_experiment(batch_size, epochs, drop_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_labels = encoder.classes_\n",
    "text_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.predict?\n",
    "#It predicts the probablity according to classes i.e business, entertainment etc ...\n",
    "prediction = model.predict(np.array([x_test[0]]))\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_label = text_labels[np.argmax(prediction)]\n",
    "predicted_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_labels = encoder.classes_\n",
    "\n",
    "for i in range(10):\n",
    "    prediction = model.predict(np.array([x_test[i]]))\n",
    "    predicted_label = text_labels[np.argmax(prediction)]\n",
    "    print(test_text.iloc[i][:50], \"...\")\n",
    "    print('Actual label:' + test_cat.iloc[i])\n",
    "    print(\"Predicted label: \" + predicted_label + \"\\n\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text.iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(np.array([x_test[3]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_label = text_labels[np.argmax(prediction)]\n",
    "predicted_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(test_text.iloc[:50], \"...\")\n",
    "print('Actual label:' + test_cat.iloc[3])\n",
    "print(\"Predicted label: \" + predicted_label + \"\\n\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
