{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Import the necessary packages\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from keras import Sequential\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"sonar.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1       2       3       4       5       6       7       8   \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "\n",
       "       9   ...      51      52      53      54      55      56      57  \\\n",
       "0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "\n",
       "       58      59  60  \n",
       "0  0.0090  0.0032   R  \n",
       "1  0.0052  0.0044   R  \n",
       "2  0.0095  0.0078   R  \n",
       "3  0.0040  0.0117   R  \n",
       "4  0.0107  0.0094   R  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of df: (208, 61)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of df:\",df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.0\n",
       "1     0.0\n",
       "2     0.0\n",
       "3     0.0\n",
       "4     0.0\n",
       "5     0.0\n",
       "6     0.0\n",
       "7     0.0\n",
       "8     0.0\n",
       "9     0.0\n",
       "10    0.0\n",
       "11    0.0\n",
       "12    0.0\n",
       "13    0.0\n",
       "14    0.0\n",
       "15    0.0\n",
       "16    0.0\n",
       "17    0.0\n",
       "18    0.0\n",
       "19    0.0\n",
       "20    0.0\n",
       "21    0.0\n",
       "22    0.0\n",
       "23    0.0\n",
       "24    0.0\n",
       "25    0.0\n",
       "26    0.0\n",
       "27    0.0\n",
       "28    0.0\n",
       "29    0.0\n",
       "     ... \n",
       "31    0.0\n",
       "32    0.0\n",
       "33    0.0\n",
       "34    0.0\n",
       "35    0.0\n",
       "36    0.0\n",
       "37    0.0\n",
       "38    0.0\n",
       "39    0.0\n",
       "40    0.0\n",
       "41    0.0\n",
       "42    0.0\n",
       "43    0.0\n",
       "44    0.0\n",
       "45    0.0\n",
       "46    0.0\n",
       "47    0.0\n",
       "48    0.0\n",
       "49    0.0\n",
       "50    0.0\n",
       "51    0.0\n",
       "52    0.0\n",
       "53    0.0\n",
       "54    0.0\n",
       "55    0.0\n",
       "56    0.0\n",
       "57    0.0\n",
       "58    0.0\n",
       "59    0.0\n",
       "60    0.0\n",
       "Length: 61, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()/df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values for outcome: ['R' 'M']\n",
      "\n",
      "Percentage of distribution for outcome-\n",
      "M    0.533654\n",
      "R    0.466346\n",
      "Name: 60, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique values for outcome:\",df[60].unique())\n",
    "print(\"\\nPercentage of distribution for outcome-\")\n",
    "print(df[60].value_counts()/df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct DataTypes: [dtype('float64'), dtype('O')]\n"
     ]
    }
   ],
   "source": [
    "#Checking the distinct datatypes in the dataset\n",
    "print(\"Distinct DataTypes:\",list(df.dtypes.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a temp dataset with the datatype of columns\n",
    "temp = pd.DataFrame(df.dtypes)\n",
    "temp.columns = [\"DataType\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
       "       51, 52, 53, 54, 55, 56, 57, 58, 59], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_columns = temp.index[temp.DataType == \"float64\"].values\n",
    "float_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DataType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   DataType\n",
       "0   float64\n",
       "1   float64\n",
       "2   float64\n",
       "3   float64\n",
       "4   float64\n",
       "5   float64\n",
       "6   float64\n",
       "7   float64\n",
       "8   float64\n",
       "9   float64\n",
       "10  float64\n",
       "11  float64\n",
       "12  float64\n",
       "13  float64\n",
       "14  float64\n",
       "15  float64\n",
       "16  float64\n",
       "17  float64\n",
       "18  float64\n",
       "19  float64\n",
       "20  float64\n",
       "21  float64\n",
       "22  float64\n",
       "23  float64\n",
       "24  float64\n",
       "25  float64\n",
       "26  float64\n",
       "27  float64\n",
       "28  float64\n",
       "29  float64\n",
       "..      ...\n",
       "31  float64\n",
       "32  float64\n",
       "33  float64\n",
       "34  float64\n",
       "35  float64\n",
       "36  float64\n",
       "37  float64\n",
       "38  float64\n",
       "39  float64\n",
       "40  float64\n",
       "41  float64\n",
       "42  float64\n",
       "43  float64\n",
       "44  float64\n",
       "45  float64\n",
       "46  float64\n",
       "47  float64\n",
       "48  float64\n",
       "49  float64\n",
       "50  float64\n",
       "51  float64\n",
       "52  float64\n",
       "53  float64\n",
       "54  float64\n",
       "55  float64\n",
       "56  float64\n",
       "57  float64\n",
       "58  float64\n",
       "59  float64\n",
       "60   object\n",
       "\n",
       "[61 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical column - \n",
      " [60]\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = temp.index[temp.DataType == \"O\"].values\n",
    "print(\"Categorical column - \\n\",categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in categorical_columns:\n",
    "    df[column] = np.where(df[column] == 'R',1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1       2       3       4       5       6       7       8   \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "\n",
       "       9   ...      51      52      53      54      55      56      57  \\\n",
       "0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "\n",
       "       58      59  60  \n",
       "0  0.0090  0.0032   1  \n",
       "1  0.0052  0.0044   1  \n",
       "2  0.0095  0.0078   1  \n",
       "3  0.0040  0.0117   1  \n",
       "4  0.0107  0.0094   1  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DataType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   DataType\n",
       "0   float64\n",
       "1   float64\n",
       "2   float64\n",
       "3   float64\n",
       "4   float64\n",
       "5   float64\n",
       "6   float64\n",
       "7   float64\n",
       "8   float64\n",
       "9   float64\n",
       "10  float64\n",
       "11  float64\n",
       "12  float64\n",
       "13  float64\n",
       "14  float64\n",
       "15  float64\n",
       "16  float64\n",
       "17  float64\n",
       "18  float64\n",
       "19  float64\n",
       "20  float64\n",
       "21  float64\n",
       "22  float64\n",
       "23  float64\n",
       "24  float64\n",
       "25  float64\n",
       "26  float64\n",
       "27  float64\n",
       "28  float64\n",
       "29  float64\n",
       "..      ...\n",
       "31  float64\n",
       "32  float64\n",
       "33  float64\n",
       "34  float64\n",
       "35  float64\n",
       "36  float64\n",
       "37  float64\n",
       "38  float64\n",
       "39  float64\n",
       "40  float64\n",
       "41  float64\n",
       "42  float64\n",
       "43  float64\n",
       "44  float64\n",
       "45  float64\n",
       "46  float64\n",
       "47  float64\n",
       "48  float64\n",
       "49  float64\n",
       "50  float64\n",
       "51  float64\n",
       "52  float64\n",
       "53  float64\n",
       "54  float64\n",
       "55  float64\n",
       "56  float64\n",
       "57  float64\n",
       "58  float64\n",
       "59  float64\n",
       "60   object\n",
       "\n",
       "[61 rows x 1 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'target' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-b7c2057dae08>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'target' is not defined"
     ]
    }
   ],
   "source": [
    "df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train: (149, 61)\n",
      "Shape of x_test: (42, 61)\n",
      "Shape of x_val: (17, 61)\n",
      "Shape of y_train: (149,)\n",
      "Shape of y_test: (42,)\n",
      "Shape of y_val: (17,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "target = 60\n",
    "\n",
    "#split the final dataset into train and test with 80:20\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df, df[target], test_size=0.2, random_state=2018)\n",
    "\n",
    "#split the train dataset further into train and validation with 90:10\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train,y_train,test_size=0.1,random_state=2018)\n",
    "\n",
    "#Check the shape of each new dataset created\n",
    "print(\"Shape of x_train:\",x_train.shape)\n",
    "print(\"Shape of x_test:\",x_test.shape)\n",
    "print(\"Shape of x_val:\",x_val.shape)\n",
    "print(\"Shape of y_train:\",y_train.shape)\n",
    "print(\"Shape of y_test:\",y_test.shape)\n",
    "print(\"Shape of y_val:\",y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>0.0076</td>\n",
       "      <td>0.0211</td>\n",
       "      <td>0.1058</td>\n",
       "      <td>0.1023</td>\n",
       "      <td>0.0440</td>\n",
       "      <td>0.0931</td>\n",
       "      <td>0.0734</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0091</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0611</td>\n",
       "      <td>0.1136</td>\n",
       "      <td>0.1203</td>\n",
       "      <td>0.0403</td>\n",
       "      <td>0.1227</td>\n",
       "      <td>0.2495</td>\n",
       "      <td>0.4566</td>\n",
       "      <td>0.6587</td>\n",
       "      <td>0.5079</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0234</td>\n",
       "      <td>0.0175</td>\n",
       "      <td>0.0352</td>\n",
       "      <td>0.0158</td>\n",
       "      <td>0.0326</td>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.0168</td>\n",
       "      <td>0.0245</td>\n",
       "      <td>0.0154</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0270</td>\n",
       "      <td>0.0450</td>\n",
       "      <td>0.0958</td>\n",
       "      <td>0.0830</td>\n",
       "      <td>0.0879</td>\n",
       "      <td>0.1220</td>\n",
       "      <td>0.1977</td>\n",
       "      <td>0.2282</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0165</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0308</td>\n",
       "      <td>0.0311</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0767</td>\n",
       "      <td>0.0771</td>\n",
       "      <td>0.0640</td>\n",
       "      <td>0.0726</td>\n",
       "      <td>0.0901</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.0274</td>\n",
       "      <td>0.0242</td>\n",
       "      <td>0.0621</td>\n",
       "      <td>0.0560</td>\n",
       "      <td>0.1129</td>\n",
       "      <td>0.0973</td>\n",
       "      <td>0.1823</td>\n",
       "      <td>0.1745</td>\n",
       "      <td>0.1440</td>\n",
       "      <td>0.1808</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0113</td>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0104</td>\n",
       "      <td>0.0161</td>\n",
       "      <td>0.0220</td>\n",
       "      <td>0.0173</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0289</td>\n",
       "      <td>0.0713</td>\n",
       "      <td>0.1075</td>\n",
       "      <td>0.1019</td>\n",
       "      <td>0.1606</td>\n",
       "      <td>0.2119</td>\n",
       "      <td>0.3061</td>\n",
       "      <td>0.2936</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.0113</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.0097</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>0.0130</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.0436</td>\n",
       "      <td>0.0624</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0349</td>\n",
       "      <td>0.0384</td>\n",
       "      <td>0.0446</td>\n",
       "      <td>0.1318</td>\n",
       "      <td>0.1375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.0654</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.0737</td>\n",
       "      <td>0.1132</td>\n",
       "      <td>0.2482</td>\n",
       "      <td>0.1257</td>\n",
       "      <td>0.1797</td>\n",
       "      <td>0.0989</td>\n",
       "      <td>0.2460</td>\n",
       "      <td>0.3422</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.0361</td>\n",
       "      <td>0.0239</td>\n",
       "      <td>0.0447</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0355</td>\n",
       "      <td>0.0440</td>\n",
       "      <td>0.0243</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0513</td>\n",
       "      <td>0.0444</td>\n",
       "      <td>0.0249</td>\n",
       "      <td>0.0637</td>\n",
       "      <td>0.0422</td>\n",
       "      <td>0.1130</td>\n",
       "      <td>0.1911</td>\n",
       "      <td>0.2475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0173</td>\n",
       "      <td>0.0163</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0194</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0309</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0228</td>\n",
       "      <td>0.0434</td>\n",
       "      <td>0.1224</td>\n",
       "      <td>0.1947</td>\n",
       "      <td>0.1661</td>\n",
       "      <td>0.1368</td>\n",
       "      <td>0.1430</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.0257</td>\n",
       "      <td>0.0447</td>\n",
       "      <td>0.0388</td>\n",
       "      <td>0.0239</td>\n",
       "      <td>0.1315</td>\n",
       "      <td>0.1323</td>\n",
       "      <td>0.1608</td>\n",
       "      <td>0.2145</td>\n",
       "      <td>0.0847</td>\n",
       "      <td>0.0561</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0153</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.0198</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0199</td>\n",
       "      <td>0.0255</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.0260</td>\n",
       "      <td>0.0192</td>\n",
       "      <td>0.0254</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0352</td>\n",
       "      <td>0.0701</td>\n",
       "      <td>0.1263</td>\n",
       "      <td>0.1080</td>\n",
       "      <td>0.1523</td>\n",
       "      <td>0.1630</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0289</td>\n",
       "      <td>0.0561</td>\n",
       "      <td>0.0929</td>\n",
       "      <td>0.1031</td>\n",
       "      <td>0.0883</td>\n",
       "      <td>0.1596</td>\n",
       "      <td>0.1908</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0308</td>\n",
       "      <td>0.0539</td>\n",
       "      <td>0.0411</td>\n",
       "      <td>0.0613</td>\n",
       "      <td>0.1039</td>\n",
       "      <td>0.1016</td>\n",
       "      <td>0.1394</td>\n",
       "      <td>0.2592</td>\n",
       "      <td>0.3745</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0181</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.0133</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0.1150</td>\n",
       "      <td>0.1163</td>\n",
       "      <td>0.0866</td>\n",
       "      <td>0.0358</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.1267</td>\n",
       "      <td>0.2417</td>\n",
       "      <td>0.2661</td>\n",
       "      <td>0.4346</td>\n",
       "      <td>0.5378</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0099</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0190</td>\n",
       "      <td>0.0141</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>0.0117</td>\n",
       "      <td>0.0069</td>\n",
       "      <td>0.0279</td>\n",
       "      <td>0.0583</td>\n",
       "      <td>0.0915</td>\n",
       "      <td>0.1267</td>\n",
       "      <td>0.1577</td>\n",
       "      <td>0.1927</td>\n",
       "      <td>0.2361</td>\n",
       "      <td>0.2169</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0.0430</td>\n",
       "      <td>0.0902</td>\n",
       "      <td>0.0833</td>\n",
       "      <td>0.0813</td>\n",
       "      <td>0.0165</td>\n",
       "      <td>0.0277</td>\n",
       "      <td>0.0569</td>\n",
       "      <td>0.2057</td>\n",
       "      <td>0.3887</td>\n",
       "      <td>0.7106</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0176</td>\n",
       "      <td>0.0197</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.0141</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0270</td>\n",
       "      <td>0.0092</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>0.0278</td>\n",
       "      <td>0.0412</td>\n",
       "      <td>0.0757</td>\n",
       "      <td>0.1026</td>\n",
       "      <td>0.1138</td>\n",
       "      <td>0.0794</td>\n",
       "      <td>0.1520</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.0088</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.0195</td>\n",
       "      <td>0.0213</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.0190</td>\n",
       "      <td>0.0319</td>\n",
       "      <td>0.0571</td>\n",
       "      <td>0.1004</td>\n",
       "      <td>0.0668</td>\n",
       "      <td>0.0691</td>\n",
       "      <td>0.0242</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0271</td>\n",
       "      <td>0.0203</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>0.0272</td>\n",
       "      <td>0.0378</td>\n",
       "      <td>0.0488</td>\n",
       "      <td>0.0848</td>\n",
       "      <td>0.1127</td>\n",
       "      <td>0.1103</td>\n",
       "      <td>0.1349</td>\n",
       "      <td>0.2337</td>\n",
       "      <td>0.3113</td>\n",
       "      <td>0.3997</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0091</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0.0968</td>\n",
       "      <td>0.0821</td>\n",
       "      <td>0.0629</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.0617</td>\n",
       "      <td>0.1207</td>\n",
       "      <td>0.0944</td>\n",
       "      <td>0.4223</td>\n",
       "      <td>0.5744</td>\n",
       "      <td>0.5025</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0303</td>\n",
       "      <td>0.0190</td>\n",
       "      <td>0.0212</td>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0535</td>\n",
       "      <td>0.0334</td>\n",
       "      <td>0.0818</td>\n",
       "      <td>0.0740</td>\n",
       "      <td>0.0324</td>\n",
       "      <td>0.0918</td>\n",
       "      <td>0.1070</td>\n",
       "      <td>0.1553</td>\n",
       "      <td>0.1234</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0190</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.0099</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.0712</td>\n",
       "      <td>0.0901</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.1497</td>\n",
       "      <td>0.1284</td>\n",
       "      <td>0.1165</td>\n",
       "      <td>0.1285</td>\n",
       "      <td>0.1684</td>\n",
       "      <td>0.1830</td>\n",
       "      <td>0.2127</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0154</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0087</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.0443</td>\n",
       "      <td>0.0446</td>\n",
       "      <td>0.0235</td>\n",
       "      <td>0.1008</td>\n",
       "      <td>0.2252</td>\n",
       "      <td>0.2611</td>\n",
       "      <td>0.2061</td>\n",
       "      <td>0.1668</td>\n",
       "      <td>0.1801</td>\n",
       "      <td>0.3083</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0274</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0141</td>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.0311</td>\n",
       "      <td>0.0491</td>\n",
       "      <td>0.0692</td>\n",
       "      <td>0.0831</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0981</td>\n",
       "      <td>0.1016</td>\n",
       "      <td>0.2025</td>\n",
       "      <td>0.0767</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0087</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0130</td>\n",
       "      <td>0.0188</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0229</td>\n",
       "      <td>0.0182</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0352</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0469</td>\n",
       "      <td>0.0737</td>\n",
       "      <td>0.1185</td>\n",
       "      <td>0.1683</td>\n",
       "      <td>0.1541</td>\n",
       "      <td>0.1466</td>\n",
       "      <td>0.2912</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0346</td>\n",
       "      <td>0.0158</td>\n",
       "      <td>0.0154</td>\n",
       "      <td>0.0109</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.0374</td>\n",
       "      <td>0.0586</td>\n",
       "      <td>0.0628</td>\n",
       "      <td>0.0534</td>\n",
       "      <td>0.0255</td>\n",
       "      <td>0.1422</td>\n",
       "      <td>0.2072</td>\n",
       "      <td>0.2734</td>\n",
       "      <td>0.3070</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0237</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0087</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>0.0113</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0126</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0099</td>\n",
       "      <td>0.0484</td>\n",
       "      <td>0.0299</td>\n",
       "      <td>0.0297</td>\n",
       "      <td>0.0652</td>\n",
       "      <td>0.1077</td>\n",
       "      <td>0.2363</td>\n",
       "      <td>0.2385</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.1882</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0173</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0139</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.0106</td>\n",
       "      <td>0.0134</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>0.0221</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0487</td>\n",
       "      <td>0.0519</td>\n",
       "      <td>0.0849</td>\n",
       "      <td>0.0812</td>\n",
       "      <td>0.1833</td>\n",
       "      <td>0.2228</td>\n",
       "      <td>0.1810</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0.0635</td>\n",
       "      <td>0.0709</td>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.1260</td>\n",
       "      <td>0.1015</td>\n",
       "      <td>0.1918</td>\n",
       "      <td>0.3362</td>\n",
       "      <td>0.3900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0087</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>0.0340</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0381</td>\n",
       "      <td>0.0257</td>\n",
       "      <td>0.0441</td>\n",
       "      <td>0.1027</td>\n",
       "      <td>0.1287</td>\n",
       "      <td>0.1850</td>\n",
       "      <td>0.2647</td>\n",
       "      <td>0.4117</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0141</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>0.0099</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.0378</td>\n",
       "      <td>0.0318</td>\n",
       "      <td>0.0423</td>\n",
       "      <td>0.0350</td>\n",
       "      <td>0.1787</td>\n",
       "      <td>0.1635</td>\n",
       "      <td>0.0887</td>\n",
       "      <td>0.0817</td>\n",
       "      <td>0.1779</td>\n",
       "      <td>0.2053</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.0409</td>\n",
       "      <td>0.0421</td>\n",
       "      <td>0.0573</td>\n",
       "      <td>0.0130</td>\n",
       "      <td>0.0183</td>\n",
       "      <td>0.1019</td>\n",
       "      <td>0.1054</td>\n",
       "      <td>0.1070</td>\n",
       "      <td>0.2302</td>\n",
       "      <td>0.2259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.0087</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.0092</td>\n",
       "      <td>0.0387</td>\n",
       "      <td>0.0530</td>\n",
       "      <td>0.1197</td>\n",
       "      <td>0.1243</td>\n",
       "      <td>0.1026</td>\n",
       "      <td>0.1239</td>\n",
       "      <td>0.0888</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0119</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0186</td>\n",
       "      <td>0.0289</td>\n",
       "      <td>0.0195</td>\n",
       "      <td>0.0515</td>\n",
       "      <td>0.0817</td>\n",
       "      <td>0.1005</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>0.1168</td>\n",
       "      <td>0.1476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0.0258</td>\n",
       "      <td>0.0433</td>\n",
       "      <td>0.0547</td>\n",
       "      <td>0.0681</td>\n",
       "      <td>0.0784</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.1296</td>\n",
       "      <td>0.1729</td>\n",
       "      <td>0.2794</td>\n",
       "      <td>0.2954</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0091</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.0162</td>\n",
       "      <td>0.0253</td>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0386</td>\n",
       "      <td>0.0645</td>\n",
       "      <td>0.0472</td>\n",
       "      <td>0.1056</td>\n",
       "      <td>0.1388</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1334</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>0.0082</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0198</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0473</td>\n",
       "      <td>0.0509</td>\n",
       "      <td>0.0819</td>\n",
       "      <td>0.1252</td>\n",
       "      <td>0.1783</td>\n",
       "      <td>0.3070</td>\n",
       "      <td>0.3008</td>\n",
       "      <td>0.2362</td>\n",
       "      <td>0.3830</td>\n",
       "      <td>0.3759</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0082</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0151</td>\n",
       "      <td>0.0320</td>\n",
       "      <td>0.0599</td>\n",
       "      <td>0.1050</td>\n",
       "      <td>0.1163</td>\n",
       "      <td>0.1734</td>\n",
       "      <td>0.1679</td>\n",
       "      <td>0.1119</td>\n",
       "      <td>0.0889</td>\n",
       "      <td>0.1205</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.0353</td>\n",
       "      <td>0.0713</td>\n",
       "      <td>0.0326</td>\n",
       "      <td>0.0272</td>\n",
       "      <td>0.0370</td>\n",
       "      <td>0.0792</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0298</td>\n",
       "      <td>0.0880</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0163</td>\n",
       "      <td>0.0242</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>0.0137</td>\n",
       "      <td>0.0297</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.0082</td>\n",
       "      <td>0.0241</td>\n",
       "      <td>0.0253</td>\n",
       "      <td>0.0279</td>\n",
       "      <td>0.0130</td>\n",
       "      <td>0.0489</td>\n",
       "      <td>0.0874</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.0087</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0230</td>\n",
       "      <td>0.0586</td>\n",
       "      <td>0.0682</td>\n",
       "      <td>0.0993</td>\n",
       "      <td>0.0717</td>\n",
       "      <td>0.0576</td>\n",
       "      <td>0.0818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0194</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>0.0489</td>\n",
       "      <td>0.0839</td>\n",
       "      <td>0.1009</td>\n",
       "      <td>0.1627</td>\n",
       "      <td>0.2071</td>\n",
       "      <td>0.2696</td>\n",
       "      <td>0.2990</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0130</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.0491</td>\n",
       "      <td>0.0279</td>\n",
       "      <td>0.0592</td>\n",
       "      <td>0.1270</td>\n",
       "      <td>0.1772</td>\n",
       "      <td>0.1908</td>\n",
       "      <td>0.2217</td>\n",
       "      <td>0.0768</td>\n",
       "      <td>0.1246</td>\n",
       "      <td>0.2028</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.0161</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0119</td>\n",
       "      <td>0.0194</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0332</td>\n",
       "      <td>0.0439</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0.0264</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>0.0342</td>\n",
       "      <td>0.0793</td>\n",
       "      <td>0.1043</td>\n",
       "      <td>0.0783</td>\n",
       "      <td>0.1417</td>\n",
       "      <td>0.1176</td>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0945</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0214</td>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0177</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.0066</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0555</td>\n",
       "      <td>0.0708</td>\n",
       "      <td>0.0618</td>\n",
       "      <td>0.1215</td>\n",
       "      <td>0.1524</td>\n",
       "      <td>0.1543</td>\n",
       "      <td>0.0391</td>\n",
       "      <td>0.0610</td>\n",
       "      <td>0.0113</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.0179</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0113</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.1070</td>\n",
       "      <td>0.0257</td>\n",
       "      <td>0.0837</td>\n",
       "      <td>0.0748</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>0.3322</td>\n",
       "      <td>0.4590</td>\n",
       "      <td>0.5526</td>\n",
       "      <td>0.5966</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0234</td>\n",
       "      <td>0.0276</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.0082</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.0265</td>\n",
       "      <td>0.0440</td>\n",
       "      <td>0.0137</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0305</td>\n",
       "      <td>0.0438</td>\n",
       "      <td>0.0341</td>\n",
       "      <td>0.0780</td>\n",
       "      <td>0.0844</td>\n",
       "      <td>0.0779</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0097</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0274</td>\n",
       "      <td>0.0248</td>\n",
       "      <td>0.0237</td>\n",
       "      <td>0.0224</td>\n",
       "      <td>0.0845</td>\n",
       "      <td>0.1488</td>\n",
       "      <td>0.1224</td>\n",
       "      <td>0.1569</td>\n",
       "      <td>0.2119</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.0069</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>0.0233</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0416</td>\n",
       "      <td>0.0547</td>\n",
       "      <td>0.0993</td>\n",
       "      <td>0.1515</td>\n",
       "      <td>0.1674</td>\n",
       "      <td>0.1513</td>\n",
       "      <td>0.1723</td>\n",
       "      <td>0.2078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0104</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0.0526</td>\n",
       "      <td>0.0563</td>\n",
       "      <td>0.1219</td>\n",
       "      <td>0.1206</td>\n",
       "      <td>0.0246</td>\n",
       "      <td>0.1022</td>\n",
       "      <td>0.0539</td>\n",
       "      <td>0.0439</td>\n",
       "      <td>0.2291</td>\n",
       "      <td>0.1632</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0339</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0335</td>\n",
       "      <td>0.0376</td>\n",
       "      <td>0.0174</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0364</td>\n",
       "      <td>0.0208</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.0335</td>\n",
       "      <td>0.0134</td>\n",
       "      <td>0.0696</td>\n",
       "      <td>0.1180</td>\n",
       "      <td>0.0348</td>\n",
       "      <td>0.1180</td>\n",
       "      <td>0.1948</td>\n",
       "      <td>0.1607</td>\n",
       "      <td>0.3036</td>\n",
       "      <td>0.4372</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0377</td>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.0130</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0088</td>\n",
       "      <td>0.0456</td>\n",
       "      <td>0.0525</td>\n",
       "      <td>0.0778</td>\n",
       "      <td>0.0931</td>\n",
       "      <td>0.0941</td>\n",
       "      <td>0.1711</td>\n",
       "      <td>0.1483</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0.0211</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0450</td>\n",
       "      <td>0.0711</td>\n",
       "      <td>0.1563</td>\n",
       "      <td>0.1518</td>\n",
       "      <td>0.1206</td>\n",
       "      <td>0.1666</td>\n",
       "      <td>0.1345</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0.0209</td>\n",
       "      <td>0.0261</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.0768</td>\n",
       "      <td>0.1064</td>\n",
       "      <td>0.1680</td>\n",
       "      <td>0.3016</td>\n",
       "      <td>0.3460</td>\n",
       "      <td>0.3314</td>\n",
       "      <td>0.4125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0372</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0127</td>\n",
       "      <td>0.0288</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0104</td>\n",
       "      <td>0.0325</td>\n",
       "      <td>0.0239</td>\n",
       "      <td>0.0807</td>\n",
       "      <td>0.1529</td>\n",
       "      <td>0.1154</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.1317</td>\n",
       "      <td>0.1370</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0127</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.0211</td>\n",
       "      <td>0.0319</td>\n",
       "      <td>0.0415</td>\n",
       "      <td>0.0286</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0438</td>\n",
       "      <td>0.1299</td>\n",
       "      <td>0.1390</td>\n",
       "      <td>0.0695</td>\n",
       "      <td>0.0568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0153</td>\n",
       "      <td>0.0106</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.0460</td>\n",
       "      <td>0.0752</td>\n",
       "      <td>0.0887</td>\n",
       "      <td>0.1015</td>\n",
       "      <td>0.0494</td>\n",
       "      <td>0.0472</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.0188</td>\n",
       "      <td>0.0370</td>\n",
       "      <td>0.0953</td>\n",
       "      <td>0.0824</td>\n",
       "      <td>0.0249</td>\n",
       "      <td>0.0488</td>\n",
       "      <td>0.1424</td>\n",
       "      <td>0.1972</td>\n",
       "      <td>0.1873</td>\n",
       "      <td>0.1806</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0113</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>149 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1       2       3       4       5       6       7       8   \\\n",
       "23   0.0115  0.0150  0.0136  0.0076  0.0211  0.1058  0.1023  0.0440  0.0931   \n",
       "135  0.0094  0.0611  0.1136  0.1203  0.0403  0.1227  0.2495  0.4566  0.6587   \n",
       "196  0.0050  0.0017  0.0270  0.0450  0.0958  0.0830  0.0879  0.1220  0.1977   \n",
       "51   0.0131  0.0068  0.0308  0.0311  0.0085  0.0767  0.0771  0.0640  0.0726   \n",
       "88   0.0274  0.0242  0.0621  0.0560  0.1129  0.0973  0.1823  0.1745  0.1440   \n",
       "158  0.0107  0.0453  0.0289  0.0713  0.1075  0.1019  0.1606  0.2119  0.3061   \n",
       "169  0.0130  0.0120  0.0436  0.0624  0.0428  0.0349  0.0384  0.0446  0.1318   \n",
       "147  0.0654  0.0649  0.0737  0.1132  0.2482  0.1257  0.1797  0.0989  0.2460   \n",
       "40   0.0068  0.0232  0.0513  0.0444  0.0249  0.0637  0.0422  0.1130  0.1911   \n",
       "94   0.0025  0.0309  0.0171  0.0228  0.0434  0.1224  0.1947  0.1661  0.1368   \n",
       "44   0.0257  0.0447  0.0388  0.0239  0.1315  0.1323  0.1608  0.2145  0.0847   \n",
       "92   0.0260  0.0192  0.0254  0.0061  0.0352  0.0701  0.1263  0.1080  0.1523   \n",
       "61   0.0135  0.0045  0.0051  0.0289  0.0561  0.0929  0.1031  0.0883  0.1596   \n",
       "182  0.0095  0.0308  0.0539  0.0411  0.0613  0.1039  0.1016  0.1394  0.2592   \n",
       "131  0.1150  0.1163  0.0866  0.0358  0.0232  0.1267  0.2417  0.2661  0.4346   \n",
       "154  0.0117  0.0069  0.0279  0.0583  0.0915  0.1267  0.1577  0.1927  0.2361   \n",
       "137  0.0430  0.0902  0.0833  0.0813  0.0165  0.0277  0.0569  0.2057  0.3887   \n",
       "18   0.0270  0.0092  0.0145  0.0278  0.0412  0.0757  0.1026  0.1138  0.0794   \n",
       "32   0.0195  0.0213  0.0058  0.0190  0.0319  0.0571  0.1004  0.0668  0.0691   \n",
       "202  0.0272  0.0378  0.0488  0.0848  0.1127  0.1103  0.1349  0.2337  0.3113   \n",
       "132  0.0968  0.0821  0.0629  0.0608  0.0617  0.1207  0.0944  0.4223  0.5744   \n",
       "149  0.0207  0.0535  0.0334  0.0818  0.0740  0.0324  0.0918  0.1070  0.1553   \n",
       "148  0.0712  0.0901  0.1276  0.1497  0.1284  0.1165  0.1285  0.1684  0.1830   \n",
       "130  0.0443  0.0446  0.0235  0.1008  0.2252  0.2611  0.2061  0.1668  0.1801   \n",
       "34   0.0311  0.0491  0.0692  0.0831  0.0079  0.0200  0.0981  0.1016  0.2025   \n",
       "16   0.0352  0.0116  0.0191  0.0469  0.0737  0.1185  0.1683  0.1541  0.1466   \n",
       "128  0.0374  0.0586  0.0628  0.0534  0.0255  0.1422  0.2072  0.2734  0.3070   \n",
       "22   0.0099  0.0484  0.0299  0.0297  0.0652  0.1077  0.2363  0.2385  0.0075   \n",
       "165  0.0221  0.0065  0.0164  0.0487  0.0519  0.0849  0.0812  0.1833  0.2228   \n",
       "176  0.0635  0.0709  0.0453  0.0333  0.0185  0.1260  0.1015  0.1918  0.3362   \n",
       "..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "185  0.0340  0.0625  0.0381  0.0257  0.0441  0.1027  0.1287  0.1850  0.2647   \n",
       "84   0.0378  0.0318  0.0423  0.0350  0.1787  0.1635  0.0887  0.0817  0.1779   \n",
       "82   0.0409  0.0421  0.0573  0.0130  0.0183  0.1019  0.1054  0.1070  0.2302   \n",
       "71   0.0036  0.0078  0.0092  0.0387  0.0530  0.1197  0.1243  0.1026  0.1239   \n",
       "168  0.0015  0.0186  0.0289  0.0195  0.0515  0.0817  0.1005  0.0124  0.1168   \n",
       "160  0.0258  0.0433  0.0547  0.0681  0.0784  0.1250  0.1296  0.1729  0.2794   \n",
       "103  0.0162  0.0253  0.0262  0.0386  0.0645  0.0472  0.1056  0.1388  0.0598   \n",
       "20   0.0473  0.0509  0.0819  0.1252  0.1783  0.3070  0.3008  0.2362  0.3830   \n",
       "26   0.0151  0.0320  0.0599  0.1050  0.1163  0.1734  0.1679  0.1119  0.0889   \n",
       "50   0.0353  0.0713  0.0326  0.0272  0.0370  0.0792  0.1083  0.0687  0.0298   \n",
       "167  0.0137  0.0297  0.0116  0.0082  0.0241  0.0253  0.0279  0.0130  0.0489   \n",
       "52   0.0087  0.0046  0.0081  0.0230  0.0586  0.0682  0.0993  0.0717  0.0576   \n",
       "81   0.0100  0.0194  0.0155  0.0489  0.0839  0.1009  0.1627  0.2071  0.2696   \n",
       "97   0.0491  0.0279  0.0592  0.1270  0.1772  0.1908  0.2217  0.0768  0.1246   \n",
       "109  0.0264  0.0071  0.0342  0.0793  0.1043  0.0783  0.1417  0.1176  0.0453   \n",
       "107  0.0428  0.0555  0.0708  0.0618  0.1215  0.1524  0.1543  0.0391  0.0610   \n",
       "134  0.1083  0.1070  0.0257  0.0837  0.0748  0.1125  0.3322  0.4590  0.5526   \n",
       "66   0.0265  0.0440  0.0137  0.0084  0.0305  0.0438  0.0341  0.0780  0.0844   \n",
       "188  0.0089  0.0274  0.0248  0.0237  0.0224  0.0845  0.1488  0.1224  0.1569   \n",
       "153  0.0233  0.0394  0.0416  0.0547  0.0993  0.1515  0.1674  0.1513  0.1723   \n",
       "142  0.0526  0.0563  0.1219  0.1206  0.0246  0.1022  0.0539  0.0439  0.2291   \n",
       "101  0.0335  0.0134  0.0696  0.1180  0.0348  0.1180  0.1948  0.1607  0.3036   \n",
       "60   0.0130  0.0006  0.0088  0.0456  0.0525  0.0778  0.0931  0.0941  0.1711   \n",
       "155  0.0211  0.0128  0.0015  0.0450  0.0711  0.1563  0.1518  0.1206  0.1666   \n",
       "0    0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "127  0.0209  0.0261  0.0120  0.0768  0.1064  0.1680  0.3016  0.3460  0.3314   \n",
       "75   0.0202  0.0104  0.0325  0.0239  0.0807  0.1529  0.1154  0.0608  0.1317   \n",
       "42   0.0211  0.0319  0.0415  0.0286  0.0121  0.0438  0.1299  0.1390  0.0695   \n",
       "79   0.0108  0.0086  0.0058  0.0460  0.0752  0.0887  0.1015  0.0494  0.0472   \n",
       "86   0.0188  0.0370  0.0953  0.0824  0.0249  0.0488  0.1424  0.1972  0.1873   \n",
       "\n",
       "         9   ...      51      52      53      54      55      56      57  \\\n",
       "23   0.0734  ...  0.0091  0.0016  0.0084  0.0064  0.0026  0.0029  0.0037   \n",
       "135  0.5079  ...  0.0234  0.0175  0.0352  0.0158  0.0326  0.0201  0.0168   \n",
       "196  0.2282  ...  0.0165  0.0056  0.0010  0.0027  0.0062  0.0024  0.0063   \n",
       "51   0.0901  ...  0.0062  0.0028  0.0040  0.0075  0.0039  0.0053  0.0013   \n",
       "88   0.1808  ...  0.0113  0.0108  0.0085  0.0047  0.0074  0.0104  0.0161   \n",
       "158  0.2936  ...  0.0164  0.0120  0.0113  0.0021  0.0097  0.0072  0.0060   \n",
       "169  0.1375  ...  0.0084  0.0100  0.0018  0.0035  0.0058  0.0011  0.0009   \n",
       "147  0.3422  ...  0.0210  0.0361  0.0239  0.0447  0.0394  0.0355  0.0440   \n",
       "40   0.2475  ...  0.0173  0.0163  0.0055  0.0045  0.0068  0.0041  0.0052   \n",
       "94   0.1430  ...  0.0149  0.0077  0.0036  0.0114  0.0085  0.0101  0.0016   \n",
       "44   0.0561  ...  0.0096  0.0153  0.0096  0.0131  0.0198  0.0025  0.0199   \n",
       "92   0.1630  ...  0.0118  0.0120  0.0051  0.0070  0.0015  0.0035  0.0008   \n",
       "61   0.1908  ...  0.0037  0.0084  0.0102  0.0096  0.0024  0.0037  0.0028   \n",
       "182  0.3745  ...  0.0181  0.0019  0.0102  0.0133  0.0040  0.0042  0.0030   \n",
       "131  0.5378  ...  0.0099  0.0065  0.0085  0.0166  0.0110  0.0190  0.0141   \n",
       "154  0.2169  ...  0.0053  0.0029  0.0020  0.0013  0.0029  0.0020  0.0062   \n",
       "137  0.7106  ...  0.0176  0.0197  0.0210  0.0141  0.0049  0.0027  0.0162   \n",
       "18   0.1520  ...  0.0084  0.0010  0.0018  0.0068  0.0039  0.0120  0.0132   \n",
       "32   0.0242  ...  0.0157  0.0074  0.0271  0.0203  0.0089  0.0095  0.0095   \n",
       "202  0.3997  ...  0.0091  0.0045  0.0043  0.0043  0.0098  0.0054  0.0051   \n",
       "132  0.5025  ...  0.0073  0.0081  0.0303  0.0190  0.0212  0.0126  0.0201   \n",
       "149  0.1234  ...  0.0033  0.0050  0.0190  0.0103  0.0121  0.0042  0.0090   \n",
       "148  0.2127  ...  0.0154  0.0156  0.0054  0.0030  0.0048  0.0087  0.0101   \n",
       "130  0.3083  ...  0.0274  0.0205  0.0141  0.0185  0.0055  0.0045  0.0115   \n",
       "34   0.0767  ...  0.0087  0.0032  0.0130  0.0188  0.0101  0.0229  0.0182   \n",
       "16   0.2912  ...  0.0346  0.0158  0.0154  0.0109  0.0048  0.0095  0.0015   \n",
       "128  0.2597  ...  0.0118  0.0063  0.0237  0.0032  0.0087  0.0124  0.0113   \n",
       "22   0.1882  ...  0.0173  0.0149  0.0115  0.0202  0.0139  0.0029  0.0160   \n",
       "165  0.1810  ...  0.0089  0.0051  0.0015  0.0075  0.0058  0.0016  0.0070   \n",
       "176  0.3900  ...  0.0048  0.0025  0.0087  0.0072  0.0095  0.0086  0.0085   \n",
       "..      ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "185  0.4117  ...  0.0141  0.0019  0.0067  0.0099  0.0042  0.0057  0.0051   \n",
       "84   0.2053  ...  0.0046  0.0044  0.0078  0.0102  0.0065  0.0061  0.0062   \n",
       "82   0.2259  ...  0.0028  0.0036  0.0105  0.0120  0.0087  0.0061  0.0061   \n",
       "71   0.0888  ...  0.0119  0.0055  0.0035  0.0036  0.0004  0.0018  0.0049   \n",
       "168  0.1476  ...  0.0108  0.0075  0.0089  0.0036  0.0029  0.0013  0.0010   \n",
       "160  0.2954  ...  0.0091  0.0062  0.0019  0.0045  0.0079  0.0031  0.0063   \n",
       "103  0.1334  ...  0.0071  0.0082  0.0232  0.0198  0.0074  0.0035  0.0100   \n",
       "20   0.3759  ...  0.0193  0.0118  0.0064  0.0042  0.0054  0.0049  0.0082   \n",
       "26   0.1205  ...  0.0061  0.0015  0.0084  0.0128  0.0054  0.0011  0.0019   \n",
       "50   0.0880  ...  0.0163  0.0242  0.0043  0.0202  0.0108  0.0037  0.0096   \n",
       "167  0.0874  ...  0.0081  0.0040  0.0025  0.0036  0.0058  0.0067  0.0035   \n",
       "52   0.0818  ...  0.0052  0.0038  0.0079  0.0114  0.0050  0.0030  0.0064   \n",
       "81   0.2990  ...  0.0130  0.0073  0.0077  0.0075  0.0060  0.0080  0.0019   \n",
       "97   0.2028  ...  0.0081  0.0129  0.0161  0.0063  0.0119  0.0194  0.0140   \n",
       "109  0.0945  ...  0.0214  0.0262  0.0177  0.0037  0.0068  0.0121  0.0077   \n",
       "107  0.0113  ...  0.0142  0.0179  0.0079  0.0060  0.0131  0.0089  0.0084   \n",
       "134  0.5966  ...  0.0180  0.0110  0.0234  0.0276  0.0032  0.0084  0.0122   \n",
       "66   0.0779  ...  0.0038  0.0187  0.0156  0.0068  0.0097  0.0073  0.0081   \n",
       "188  0.2119  ...  0.0096  0.0103  0.0093  0.0025  0.0044  0.0021  0.0069   \n",
       "153  0.2078  ...  0.0104  0.0062  0.0026  0.0025  0.0061  0.0038  0.0101   \n",
       "142  0.1632  ...  0.0339  0.0149  0.0335  0.0376  0.0174  0.0132  0.0103   \n",
       "101  0.4372  ...  0.0244  0.0232  0.0093  0.0159  0.0193  0.0032  0.0377   \n",
       "60   0.1483  ...  0.0078  0.0041  0.0013  0.0011  0.0045  0.0039  0.0022   \n",
       "155  0.1345  ...  0.0117  0.0023  0.0047  0.0049  0.0031  0.0024  0.0039   \n",
       "0    0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "127  0.4125  ...  0.0057  0.0159  0.0085  0.0372  0.0101  0.0127  0.0288   \n",
       "75   0.1370  ...  0.0127  0.0081  0.0067  0.0043  0.0065  0.0049  0.0054   \n",
       "42   0.0568  ...  0.0090  0.0042  0.0153  0.0106  0.0020  0.0105  0.0049   \n",
       "79   0.0393  ...  0.0029  0.0078  0.0114  0.0083  0.0058  0.0003  0.0023   \n",
       "86   0.1806  ...  0.0093  0.0033  0.0113  0.0030  0.0057  0.0090  0.0057   \n",
       "\n",
       "         58      59  60  \n",
       "23   0.0070  0.0041   1  \n",
       "135  0.0245  0.0154   0  \n",
       "196  0.0017  0.0028   0  \n",
       "51   0.0052  0.0023   1  \n",
       "88   0.0220  0.0173   1  \n",
       "158  0.0017  0.0036   0  \n",
       "169  0.0033  0.0026   0  \n",
       "147  0.0243  0.0098   0  \n",
       "40   0.0194  0.0105   1  \n",
       "94   0.0028  0.0014   1  \n",
       "44   0.0255  0.0180   1  \n",
       "92   0.0044  0.0077   1  \n",
       "61   0.0030  0.0030   1  \n",
       "182  0.0031  0.0033   0  \n",
       "131  0.0068  0.0086   0  \n",
       "154  0.0026  0.0052   0  \n",
       "137  0.0059  0.0021   0  \n",
       "18   0.0070  0.0088   1  \n",
       "32   0.0021  0.0053   1  \n",
       "202  0.0065  0.0103   0  \n",
       "132  0.0210  0.0041   0  \n",
       "149  0.0070  0.0099   0  \n",
       "148  0.0095  0.0068   0  \n",
       "130  0.0152  0.0100   0  \n",
       "34   0.0046  0.0038   1  \n",
       "16   0.0073  0.0067   1  \n",
       "128  0.0098  0.0126   0  \n",
       "22   0.0106  0.0134   1  \n",
       "165  0.0074  0.0038   0  \n",
       "176  0.0040  0.0051   0  \n",
       "..      ...     ...  ..  \n",
       "185  0.0033  0.0058   0  \n",
       "84   0.0043  0.0053   1  \n",
       "82   0.0030  0.0078   1  \n",
       "71   0.0024  0.0016   1  \n",
       "168  0.0032  0.0047   0  \n",
       "160  0.0048  0.0050   0  \n",
       "103  0.0048  0.0019   0  \n",
       "20   0.0028  0.0027   1  \n",
       "26   0.0023  0.0062   1  \n",
       "50   0.0093  0.0053   1  \n",
       "167  0.0043  0.0033   0  \n",
       "52   0.0058  0.0030   1  \n",
       "81   0.0053  0.0019   1  \n",
       "97   0.0332  0.0439   0  \n",
       "109  0.0078  0.0066   0  \n",
       "107  0.0113  0.0049   0  \n",
       "134  0.0082  0.0143   0  \n",
       "66   0.0086  0.0095   1  \n",
       "188  0.0060  0.0018   0  \n",
       "153  0.0078  0.0006   0  \n",
       "142  0.0364  0.0208   0  \n",
       "101  0.0126  0.0156   0  \n",
       "60   0.0023  0.0016   1  \n",
       "155  0.0051  0.0015   0  \n",
       "0    0.0090  0.0032   1  \n",
       "127  0.0129  0.0023   0  \n",
       "75   0.0073  0.0054   1  \n",
       "42   0.0070  0.0080   1  \n",
       "79   0.0026  0.0027   1  \n",
       "86   0.0068  0.0024   1  \n",
       "\n",
       "[149 rows x 61 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 149 samples, validate on 17 samples\n",
      "Epoch 1/3\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.6073 - acc: 0.6913 - val_loss: 0.5610 - val_acc: 0.8235\n",
      "Epoch 2/3\n",
      "149/149 [==============================] - 0s 654us/step - loss: 0.4794 - acc: 0.9597 - val_loss: 0.4531 - val_acc: 1.0000\n",
      "Epoch 3/3\n",
      "149/149 [==============================] - 0s 477us/step - loss: 0.3890 - acc: 0.9866 - val_loss: 0.3693 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x202c8258d68>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "#Design the deep neural network [Small + 1 layer]\n",
    "model  = Sequential()\n",
    "model.add(Dense(256, input_dim = x_train.shape[1] ,activation=\"relu\"))\n",
    "model.add(Dense(1,activation = \"sigmoid\")) #activation = sigmoid for binary classification\n",
    "\n",
    "model.compile(optimizer = \"Adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(x_train,y_train, validation_data = (x_val,y_val),epochs=3, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 149 samples, validate on 17 samples\n",
      "Epoch 1/50\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.7328 - acc: 0.5101 - val_loss: 0.7337 - val_acc: 0.4706\n",
      "Epoch 2/50\n",
      "149/149 [==============================] - 0s 596us/step - loss: 0.7026 - acc: 0.5168 - val_loss: 0.7073 - val_acc: 0.4706\n",
      "Epoch 3/50\n",
      "149/149 [==============================] - 0s 651us/step - loss: 0.6792 - acc: 0.5235 - val_loss: 0.6813 - val_acc: 0.4706\n",
      "Epoch 4/50\n",
      "149/149 [==============================] - 0s 600us/step - loss: 0.6591 - acc: 0.6040 - val_loss: 0.6657 - val_acc: 0.4706\n",
      "Epoch 5/50\n",
      "149/149 [==============================] - 0s 756us/step - loss: 0.6418 - acc: 0.6577 - val_loss: 0.6487 - val_acc: 0.5882\n",
      "Epoch 6/50\n",
      "149/149 [==============================] - 0s 794us/step - loss: 0.6259 - acc: 0.7114 - val_loss: 0.6330 - val_acc: 0.7059\n",
      "Epoch 7/50\n",
      "149/149 [==============================] - 0s 809us/step - loss: 0.6107 - acc: 0.7047 - val_loss: 0.6201 - val_acc: 0.7647\n",
      "Epoch 8/50\n",
      "149/149 [==============================] - 0s 767us/step - loss: 0.5910 - acc: 0.8121 - val_loss: 0.6020 - val_acc: 0.8235\n",
      "Epoch 9/50\n",
      "149/149 [==============================] - 0s 766us/step - loss: 0.5727 - acc: 0.8121 - val_loss: 0.5860 - val_acc: 0.8235\n",
      "Epoch 10/50\n",
      "149/149 [==============================] - 0s 761us/step - loss: 0.5555 - acc: 0.8322 - val_loss: 0.5658 - val_acc: 0.8235\n",
      "Epoch 11/50\n",
      "149/149 [==============================] - 0s 767us/step - loss: 0.5367 - acc: 0.9060 - val_loss: 0.5488 - val_acc: 0.8235\n",
      "Epoch 12/50\n",
      "149/149 [==============================] - 0s 788us/step - loss: 0.5175 - acc: 0.9128 - val_loss: 0.5300 - val_acc: 0.8824\n",
      "Epoch 13/50\n",
      "149/149 [==============================] - 0s 807us/step - loss: 0.4975 - acc: 0.9262 - val_loss: 0.5109 - val_acc: 0.8824\n",
      "Epoch 14/50\n",
      "149/149 [==============================] - 0s 790us/step - loss: 0.4802 - acc: 0.9195 - val_loss: 0.4958 - val_acc: 0.8824\n",
      "Epoch 15/50\n",
      "149/149 [==============================] - 0s 775us/step - loss: 0.4567 - acc: 0.9329 - val_loss: 0.4701 - val_acc: 1.0000\n",
      "Epoch 16/50\n",
      "149/149 [==============================] - 0s 788us/step - loss: 0.4394 - acc: 0.9530 - val_loss: 0.4494 - val_acc: 1.0000\n",
      "Epoch 17/50\n",
      "149/149 [==============================] - 0s 794us/step - loss: 0.4213 - acc: 0.9597 - val_loss: 0.4349 - val_acc: 1.0000\n",
      "Epoch 18/50\n",
      "149/149 [==============================] - 0s 812us/step - loss: 0.4011 - acc: 0.9597 - val_loss: 0.4125 - val_acc: 1.0000\n",
      "Epoch 19/50\n",
      "149/149 [==============================] - 0s 794us/step - loss: 0.3836 - acc: 0.9732 - val_loss: 0.3942 - val_acc: 1.0000\n",
      "Epoch 20/50\n",
      "149/149 [==============================] - 0s 786us/step - loss: 0.3665 - acc: 0.9597 - val_loss: 0.3816 - val_acc: 1.0000\n",
      "Epoch 21/50\n",
      "149/149 [==============================] - 0s 819us/step - loss: 0.3488 - acc: 0.9664 - val_loss: 0.3583 - val_acc: 1.0000\n",
      "Epoch 22/50\n",
      "149/149 [==============================] - 0s 825us/step - loss: 0.3335 - acc: 0.9866 - val_loss: 0.3411 - val_acc: 1.0000\n",
      "Epoch 23/50\n",
      "149/149 [==============================] - 0s 773us/step - loss: 0.3170 - acc: 0.9799 - val_loss: 0.3277 - val_acc: 1.0000\n",
      "Epoch 24/50\n",
      "149/149 [==============================] - 0s 803us/step - loss: 0.3027 - acc: 0.9799 - val_loss: 0.3101 - val_acc: 1.0000\n",
      "Epoch 25/50\n",
      "149/149 [==============================] - 0s 776us/step - loss: 0.2878 - acc: 0.9866 - val_loss: 0.2961 - val_acc: 1.0000\n",
      "Epoch 26/50\n",
      "149/149 [==============================] - 0s 772us/step - loss: 0.2748 - acc: 0.9866 - val_loss: 0.2802 - val_acc: 1.0000\n",
      "Epoch 27/50\n",
      "149/149 [==============================] - 0s 785us/step - loss: 0.2614 - acc: 0.9866 - val_loss: 0.2654 - val_acc: 1.0000\n",
      "Epoch 28/50\n",
      "149/149 [==============================] - 0s 770us/step - loss: 0.2500 - acc: 0.9933 - val_loss: 0.2546 - val_acc: 1.0000\n",
      "Epoch 29/50\n",
      "149/149 [==============================] - 0s 779us/step - loss: 0.2374 - acc: 0.9933 - val_loss: 0.2434 - val_acc: 1.0000\n",
      "Epoch 30/50\n",
      "149/149 [==============================] - 0s 810us/step - loss: 0.2261 - acc: 0.9933 - val_loss: 0.2281 - val_acc: 1.0000\n",
      "Epoch 31/50\n",
      "149/149 [==============================] - 0s 817us/step - loss: 0.2162 - acc: 0.9933 - val_loss: 0.2209 - val_acc: 1.0000\n",
      "Epoch 32/50\n",
      "149/149 [==============================] - 0s 790us/step - loss: 0.2044 - acc: 0.9933 - val_loss: 0.2062 - val_acc: 1.0000\n",
      "Epoch 33/50\n",
      "149/149 [==============================] - 0s 807us/step - loss: 0.1959 - acc: 0.9933 - val_loss: 0.1950 - val_acc: 1.0000\n",
      "Epoch 34/50\n",
      "149/149 [==============================] - 0s 767us/step - loss: 0.1869 - acc: 0.9933 - val_loss: 0.1905 - val_acc: 1.0000\n",
      "Epoch 35/50\n",
      "149/149 [==============================] - 0s 792us/step - loss: 0.1792 - acc: 0.9933 - val_loss: 0.1746 - val_acc: 1.0000\n",
      "Epoch 36/50\n",
      "149/149 [==============================] - 0s 772us/step - loss: 0.1677 - acc: 0.9933 - val_loss: 0.1700 - val_acc: 1.0000\n",
      "Epoch 37/50\n",
      "149/149 [==============================] - 0s 755us/step - loss: 0.1591 - acc: 0.9933 - val_loss: 0.1598 - val_acc: 1.0000\n",
      "Epoch 38/50\n",
      "149/149 [==============================] - 0s 886us/step - loss: 0.1504 - acc: 0.9933 - val_loss: 0.1460 - val_acc: 1.0000\n",
      "Epoch 39/50\n",
      "149/149 [==============================] - 0s 760us/step - loss: 0.1413 - acc: 0.9933 - val_loss: 0.1385 - val_acc: 1.0000\n",
      "Epoch 40/50\n",
      "149/149 [==============================] - 0s 813us/step - loss: 0.1341 - acc: 0.9933 - val_loss: 0.1319 - val_acc: 1.0000\n",
      "Epoch 41/50\n",
      "149/149 [==============================] - 0s 776us/step - loss: 0.1270 - acc: 0.9933 - val_loss: 0.1219 - val_acc: 1.0000\n",
      "Epoch 42/50\n",
      "149/149 [==============================] - 0s 777us/step - loss: 0.1204 - acc: 0.9933 - val_loss: 0.1162 - val_acc: 1.0000\n",
      "Epoch 43/50\n",
      "149/149 [==============================] - 0s 797us/step - loss: 0.1144 - acc: 0.9933 - val_loss: 0.1097 - val_acc: 1.0000\n",
      "Epoch 44/50\n",
      "149/149 [==============================] - 0s 771us/step - loss: 0.1085 - acc: 0.9933 - val_loss: 0.1056 - val_acc: 1.0000\n",
      "Epoch 45/50\n",
      "149/149 [==============================] - 0s 784us/step - loss: 0.1031 - acc: 0.9933 - val_loss: 0.0992 - val_acc: 1.0000\n",
      "Epoch 46/50\n",
      "149/149 [==============================] - 0s 813us/step - loss: 0.0978 - acc: 0.9933 - val_loss: 0.0939 - val_acc: 1.0000\n",
      "Epoch 47/50\n",
      "149/149 [==============================] - 0s 812us/step - loss: 0.0931 - acc: 0.9933 - val_loss: 0.0886 - val_acc: 1.0000\n",
      "Epoch 48/50\n",
      "149/149 [==============================] - 0s 818us/step - loss: 0.0890 - acc: 0.9933 - val_loss: 0.0860 - val_acc: 1.0000\n",
      "Epoch 49/50\n",
      "149/149 [==============================] - 0s 773us/step - loss: 0.0845 - acc: 1.0000 - val_loss: 0.0800 - val_acc: 1.0000\n",
      "Epoch 50/50\n",
      "149/149 [==============================] - 0s 764us/step - loss: 0.0813 - acc: 1.0000 - val_loss: 0.0756 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2037cde5fd0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "#Design the deep neural network [Small + 1 layer]\n",
    "model  = Sequential()\n",
    "model.add(Dense(16, input_dim = x_train.shape[1] ,activation=\"relu\"))\n",
    "model.add(Dense(1,activation = \"sigmoid\")) #activation = sigmoid for binary classification\n",
    "\n",
    "model.compile(optimizer = \"Adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(x_train,y_train, validation_data = (x_val,y_val),epochs=50, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 149 samples, validate on 17 samples\n",
      "Epoch 1/50\n",
      "149/149 [==============================] - 1s 6ms/step - loss: 0.6716 - acc: 0.5906 - val_loss: 0.6091 - val_acc: 0.9412\n",
      "Epoch 2/50\n",
      "149/149 [==============================] - 0s 170us/step - loss: 0.5787 - acc: 0.9530 - val_loss: 0.5422 - val_acc: 1.0000\n",
      "Epoch 3/50\n",
      "149/149 [==============================] - 0s 138us/step - loss: 0.5016 - acc: 0.9933 - val_loss: 0.4591 - val_acc: 1.0000\n",
      "Epoch 4/50\n",
      "149/149 [==============================] - 0s 138us/step - loss: 0.4172 - acc: 1.0000 - val_loss: 0.3787 - val_acc: 1.0000\n",
      "Epoch 5/50\n",
      "149/149 [==============================] - 0s 123us/step - loss: 0.3347 - acc: 0.9933 - val_loss: 0.3032 - val_acc: 1.0000\n",
      "Epoch 6/50\n",
      "149/149 [==============================] - 0s 125us/step - loss: 0.2585 - acc: 1.0000 - val_loss: 0.2289 - val_acc: 1.0000\n",
      "Epoch 7/50\n",
      "149/149 [==============================] - 0s 160us/step - loss: 0.1905 - acc: 1.0000 - val_loss: 0.1698 - val_acc: 1.0000\n",
      "Epoch 8/50\n",
      "149/149 [==============================] - 0s 138us/step - loss: 0.1349 - acc: 1.0000 - val_loss: 0.1156 - val_acc: 1.0000\n",
      "Epoch 9/50\n",
      "149/149 [==============================] - 0s 137us/step - loss: 0.0916 - acc: 1.0000 - val_loss: 0.0782 - val_acc: 1.0000\n",
      "Epoch 10/50\n",
      "149/149 [==============================] - 0s 127us/step - loss: 0.0628 - acc: 1.0000 - val_loss: 0.0518 - val_acc: 1.0000\n",
      "Epoch 11/50\n",
      "149/149 [==============================] - 0s 154us/step - loss: 0.0404 - acc: 1.0000 - val_loss: 0.0344 - val_acc: 1.0000\n",
      "Epoch 12/50\n",
      "149/149 [==============================] - 0s 118us/step - loss: 0.0270 - acc: 1.0000 - val_loss: 0.0239 - val_acc: 1.0000\n",
      "Epoch 13/50\n",
      "149/149 [==============================] - 0s 166us/step - loss: 0.0187 - acc: 1.0000 - val_loss: 0.0162 - val_acc: 1.0000\n",
      "Epoch 14/50\n",
      "149/149 [==============================] - 0s 202us/step - loss: 0.0131 - acc: 1.0000 - val_loss: 0.0117 - val_acc: 1.0000\n",
      "Epoch 15/50\n",
      "149/149 [==============================] - 0s 202us/step - loss: 0.0096 - acc: 1.0000 - val_loss: 0.0085 - val_acc: 1.0000\n",
      "Epoch 16/50\n",
      "149/149 [==============================] - 0s 193us/step - loss: 0.0074 - acc: 1.0000 - val_loss: 0.0063 - val_acc: 1.0000\n",
      "Epoch 17/50\n",
      "149/149 [==============================] - 0s 200us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 0.0051 - val_acc: 1.0000\n",
      "Epoch 18/50\n",
      "149/149 [==============================] - 0s 196us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "Epoch 19/50\n",
      "149/149 [==============================] - 0s 220us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 20/50\n",
      "149/149 [==============================] - 0s 213us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 21/50\n",
      "149/149 [==============================] - 0s 200us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 22/50\n",
      "149/149 [==============================] - 0s 259us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 23/50\n",
      "149/149 [==============================] - 0s 206us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 24/50\n",
      "149/149 [==============================] - 0s 221us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 25/50\n",
      "149/149 [==============================] - 0s 184us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 26/50\n",
      "149/149 [==============================] - 0s 176us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 27/50\n",
      "149/149 [==============================] - 0s 175us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 28/50\n",
      "149/149 [==============================] - 0s 184us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 29/50\n",
      "149/149 [==============================] - 0s 200us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 30/50\n",
      "149/149 [==============================] - 0s 179us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 31/50\n",
      "149/149 [==============================] - 0s 178us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 32/50\n",
      "149/149 [==============================] - 0s 191us/step - loss: 9.8461e-04 - acc: 1.0000 - val_loss: 9.6446e-04 - val_acc: 1.0000\n",
      "Epoch 33/50\n",
      "149/149 [==============================] - 0s 169us/step - loss: 9.1408e-04 - acc: 1.0000 - val_loss: 9.2010e-04 - val_acc: 1.0000\n",
      "Epoch 34/50\n",
      "149/149 [==============================] - 0s 172us/step - loss: 8.4954e-04 - acc: 1.0000 - val_loss: 8.9680e-04 - val_acc: 1.0000\n",
      "Epoch 35/50\n",
      "149/149 [==============================] - 0s 191us/step - loss: 8.0535e-04 - acc: 1.0000 - val_loss: 8.7046e-04 - val_acc: 1.0000\n",
      "Epoch 36/50\n",
      "149/149 [==============================] - 0s 153us/step - loss: 7.6475e-04 - acc: 1.0000 - val_loss: 8.2998e-04 - val_acc: 1.0000\n",
      "Epoch 37/50\n",
      "149/149 [==============================] - 0s 156us/step - loss: 7.1939e-04 - acc: 1.0000 - val_loss: 7.7085e-04 - val_acc: 1.0000\n",
      "Epoch 38/50\n",
      "149/149 [==============================] - 0s 137us/step - loss: 6.8259e-04 - acc: 1.0000 - val_loss: 7.1540e-04 - val_acc: 1.0000\n",
      "Epoch 39/50\n",
      "149/149 [==============================] - 0s 131us/step - loss: 6.5421e-04 - acc: 1.0000 - val_loss: 6.7450e-04 - val_acc: 1.0000\n",
      "Epoch 40/50\n",
      "149/149 [==============================] - 0s 132us/step - loss: 6.2418e-04 - acc: 1.0000 - val_loss: 6.4830e-04 - val_acc: 1.0000\n",
      "Epoch 41/50\n",
      "149/149 [==============================] - 0s 141us/step - loss: 5.9493e-04 - acc: 1.0000 - val_loss: 6.3060e-04 - val_acc: 1.0000\n",
      "Epoch 42/50\n",
      "149/149 [==============================] - 0s 132us/step - loss: 5.6186e-04 - acc: 1.0000 - val_loss: 6.1453e-04 - val_acc: 1.0000\n",
      "Epoch 43/50\n",
      "149/149 [==============================] - 0s 133us/step - loss: 5.3874e-04 - acc: 1.0000 - val_loss: 6.0146e-04 - val_acc: 1.0000\n",
      "Epoch 44/50\n",
      "149/149 [==============================] - 0s 144us/step - loss: 5.1707e-04 - acc: 1.0000 - val_loss: 5.7856e-04 - val_acc: 1.0000\n",
      "Epoch 45/50\n",
      "149/149 [==============================] - 0s 140us/step - loss: 4.9619e-04 - acc: 1.0000 - val_loss: 5.5836e-04 - val_acc: 1.0000\n",
      "Epoch 46/50\n",
      "149/149 [==============================] - 0s 131us/step - loss: 4.7644e-04 - acc: 1.0000 - val_loss: 5.3416e-04 - val_acc: 1.0000\n",
      "Epoch 47/50\n",
      "149/149 [==============================] - 0s 122us/step - loss: 4.5590e-04 - acc: 1.0000 - val_loss: 5.0472e-04 - val_acc: 1.0000\n",
      "Epoch 48/50\n",
      "149/149 [==============================] - 0s 144us/step - loss: 4.3563e-04 - acc: 1.0000 - val_loss: 4.7416e-04 - val_acc: 1.0000\n",
      "Epoch 49/50\n",
      "149/149 [==============================] - 0s 129us/step - loss: 4.2000e-04 - acc: 1.0000 - val_loss: 4.5121e-04 - val_acc: 1.0000\n",
      "Epoch 50/50\n",
      "149/149 [==============================] - 0s 150us/step - loss: 4.0587e-04 - acc: 1.0000 - val_loss: 4.3459e-04 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20382ef48d0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Design the deep neural network [Small + 2 layers]\n",
    "model  = Sequential()\n",
    "model.add(Dense(256,input_dim = x_train.shape[1],activation=\"relu\"))\n",
    "model.add(Dense(256,activation=\"relu\"))\n",
    "model.add(Dense(1,activation = \"sigmoid\"))\n",
    "\n",
    "model.compile(optimizer = \"Adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(x_train,y_train, validation_data = (x_val,y_val),epochs=50, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gulraiz\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int32, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Gulraiz\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DataConversionWarning: Data with input dtype int32, float64 were all converted to float64 by StandardScaler.\n",
      "  \n",
      "C:\\Users\\Gulraiz\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DataConversionWarning: Data with input dtype int32, float64 were all converted to float64 by StandardScaler.\n",
      "  import sys\n",
      "C:\\Users\\Gulraiz\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: DataConversionWarning: Data with input dtype int32, float64 were all converted to float64 by StandardScaler.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "x_val_scaled = scaler.transform(x_val)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 149 samples, validate on 17 samples\n",
      "Epoch 1/200\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.8090 - acc: 0.4698 - val_loss: 0.6716 - val_acc: 0.4706\n",
      "Epoch 2/200\n",
      "149/149 [==============================] - 0s 915us/step - loss: 0.5930 - acc: 0.6711 - val_loss: 0.5753 - val_acc: 0.6471\n",
      "Epoch 3/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.4789 - acc: 0.8054 - val_loss: 0.4928 - val_acc: 0.7059\n",
      "Epoch 4/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.3926 - acc: 0.8523 - val_loss: 0.4172 - val_acc: 0.8235\n",
      "Epoch 5/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.3265 - acc: 0.8792 - val_loss: 0.3523 - val_acc: 0.8235\n",
      "Epoch 6/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.2695 - acc: 0.9262 - val_loss: 0.3007 - val_acc: 0.8824\n",
      "Epoch 7/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.2197 - acc: 0.9463 - val_loss: 0.2461 - val_acc: 0.9412\n",
      "Epoch 8/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.1720 - acc: 0.9597 - val_loss: 0.2177 - val_acc: 0.9412\n",
      "Epoch 9/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.1343 - acc: 0.9799 - val_loss: 0.1947 - val_acc: 0.9412\n",
      "Epoch 10/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.1049 - acc: 0.9866 - val_loss: 0.1619 - val_acc: 0.9412\n",
      "Epoch 11/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0810 - acc: 1.0000 - val_loss: 0.1429 - val_acc: 0.9412\n",
      "Epoch 12/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0614 - acc: 1.0000 - val_loss: 0.1241 - val_acc: 0.9412\n",
      "Epoch 13/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0461 - acc: 1.0000 - val_loss: 0.1098 - val_acc: 0.9412\n",
      "Epoch 14/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0350 - acc: 1.0000 - val_loss: 0.1007 - val_acc: 0.9412\n",
      "Epoch 15/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0274 - acc: 1.0000 - val_loss: 0.0948 - val_acc: 0.9412\n",
      "Epoch 16/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0214 - acc: 1.0000 - val_loss: 0.0756 - val_acc: 1.0000\n",
      "Epoch 17/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0172 - acc: 1.0000 - val_loss: 0.0742 - val_acc: 1.0000\n",
      "Epoch 18/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0139 - acc: 1.0000 - val_loss: 0.0655 - val_acc: 1.0000\n",
      "Epoch 19/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0115 - acc: 1.0000 - val_loss: 0.0612 - val_acc: 1.0000\n",
      "Epoch 20/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0096 - acc: 1.0000 - val_loss: 0.0564 - val_acc: 1.0000\n",
      "Epoch 21/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0082 - acc: 1.0000 - val_loss: 0.0533 - val_acc: 1.0000\n",
      "Epoch 22/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0070 - acc: 1.0000 - val_loss: 0.0526 - val_acc: 1.0000\n",
      "Epoch 23/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0061 - acc: 1.0000 - val_loss: 0.0483 - val_acc: 1.0000\n",
      "Epoch 24/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.0457 - val_acc: 1.0000\n",
      "Epoch 25/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.0445 - val_acc: 1.0000\n",
      "Epoch 26/200\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.0436 - val_acc: 1.0000\n",
      "Epoch 27/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.0408 - val_acc: 1.0000\n",
      "Epoch 28/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0392 - val_acc: 1.0000\n",
      "Epoch 29/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0377 - val_acc: 1.0000\n",
      "Epoch 30/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0362 - val_acc: 1.0000\n",
      "Epoch 31/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0352 - val_acc: 1.0000\n",
      "Epoch 32/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0342 - val_acc: 1.0000\n",
      "Epoch 33/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0333 - val_acc: 1.0000\n",
      "Epoch 34/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0322 - val_acc: 1.0000\n",
      "Epoch 35/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0317 - val_acc: 1.0000\n",
      "Epoch 36/200\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0304 - val_acc: 1.0000\n",
      "Epoch 37/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0295 - val_acc: 1.0000\n",
      "Epoch 38/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0289 - val_acc: 1.0000\n",
      "Epoch 39/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0283 - val_acc: 1.0000\n",
      "Epoch 40/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0280 - val_acc: 1.0000\n",
      "Epoch 41/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0273 - val_acc: 1.0000\n",
      "Epoch 42/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0262 - val_acc: 1.0000\n",
      "Epoch 43/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0260 - val_acc: 1.0000\n",
      "Epoch 44/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 9.8033e-04 - acc: 1.0000 - val_loss: 0.0253 - val_acc: 1.0000\n",
      "Epoch 45/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 9.2655e-04 - acc: 1.0000 - val_loss: 0.0250 - val_acc: 1.0000\n",
      "Epoch 46/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 8.7696e-04 - acc: 1.0000 - val_loss: 0.0246 - val_acc: 1.0000\n",
      "Epoch 47/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 8.2938e-04 - acc: 1.0000 - val_loss: 0.0241 - val_acc: 1.0000\n",
      "Epoch 48/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 7.8698e-04 - acc: 1.0000 - val_loss: 0.0234 - val_acc: 1.0000\n",
      "Epoch 49/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 7.4713e-04 - acc: 1.0000 - val_loss: 0.0231 - val_acc: 1.0000\n",
      "Epoch 50/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 7.0932e-04 - acc: 1.0000 - val_loss: 0.0226 - val_acc: 1.0000\n",
      "Epoch 51/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 6.7650e-04 - acc: 1.0000 - val_loss: 0.0225 - val_acc: 1.0000\n",
      "Epoch 52/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 6.4412e-04 - acc: 1.0000 - val_loss: 0.0218 - val_acc: 1.0000\n",
      "Epoch 53/200\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 6.1402e-04 - acc: 1.0000 - val_loss: 0.0215 - val_acc: 1.0000\n",
      "Epoch 54/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 5.8491e-04 - acc: 1.0000 - val_loss: 0.0210 - val_acc: 1.0000\n",
      "Epoch 55/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 5.5976e-04 - acc: 1.0000 - val_loss: 0.0209 - val_acc: 1.0000\n",
      "Epoch 56/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 5.3353e-04 - acc: 1.0000 - val_loss: 0.0205 - val_acc: 1.0000\n",
      "Epoch 57/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 5.1198e-04 - acc: 1.0000 - val_loss: 0.0199 - val_acc: 1.0000\n",
      "Epoch 58/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 4.8846e-04 - acc: 1.0000 - val_loss: 0.0198 - val_acc: 1.0000\n",
      "Epoch 59/200\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 4.6853e-04 - acc: 1.0000 - val_loss: 0.0196 - val_acc: 1.0000\n",
      "Epoch 60/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 4.4956e-04 - acc: 1.0000 - val_loss: 0.0193 - val_acc: 1.0000\n",
      "Epoch 61/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149/149 [==============================] - 0s 2ms/step - loss: 4.3114e-04 - acc: 1.0000 - val_loss: 0.0190 - val_acc: 1.0000\n",
      "Epoch 62/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 4.1446e-04 - acc: 1.0000 - val_loss: 0.0187 - val_acc: 1.0000\n",
      "Epoch 63/200\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 3.9801e-04 - acc: 1.0000 - val_loss: 0.0185 - val_acc: 1.0000\n",
      "Epoch 64/200\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 3.8294e-04 - acc: 1.0000 - val_loss: 0.0182 - val_acc: 1.0000\n",
      "Epoch 65/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 3.6765e-04 - acc: 1.0000 - val_loss: 0.0181 - val_acc: 1.0000\n",
      "Epoch 66/200\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 3.5442e-04 - acc: 1.0000 - val_loss: 0.0176 - val_acc: 1.0000\n",
      "Epoch 67/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 3.4155e-04 - acc: 1.0000 - val_loss: 0.0175 - val_acc: 1.0000\n",
      "Epoch 68/200\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 3.2910e-04 - acc: 1.0000 - val_loss: 0.0171 - val_acc: 1.0000\n",
      "Epoch 69/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 3.1740e-04 - acc: 1.0000 - val_loss: 0.0168 - val_acc: 1.0000\n",
      "Epoch 70/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 3.0572e-04 - acc: 1.0000 - val_loss: 0.0166 - val_acc: 1.0000\n",
      "Epoch 71/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 2.9537e-04 - acc: 1.0000 - val_loss: 0.0165 - val_acc: 1.0000\n",
      "Epoch 72/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 2.8477e-04 - acc: 1.0000 - val_loss: 0.0162 - val_acc: 1.0000\n",
      "Epoch 73/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 2.7551e-04 - acc: 1.0000 - val_loss: 0.0161 - val_acc: 1.0000\n",
      "Epoch 74/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 2.6601e-04 - acc: 1.0000 - val_loss: 0.0159 - val_acc: 1.0000\n",
      "Epoch 75/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 2.5715e-04 - acc: 1.0000 - val_loss: 0.0157 - val_acc: 1.0000\n",
      "Epoch 76/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 2.4949e-04 - acc: 1.0000 - val_loss: 0.0155 - val_acc: 1.0000\n",
      "Epoch 77/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 2.4074e-04 - acc: 1.0000 - val_loss: 0.0152 - val_acc: 1.0000\n",
      "Epoch 78/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 2.3295e-04 - acc: 1.0000 - val_loss: 0.0151 - val_acc: 1.0000\n",
      "Epoch 79/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 2.2593e-04 - acc: 1.0000 - val_loss: 0.0149 - val_acc: 1.0000\n",
      "Epoch 80/200\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 2.1902e-04 - acc: 1.0000 - val_loss: 0.0147 - val_acc: 1.0000\n",
      "Epoch 81/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 2.1161e-04 - acc: 1.0000 - val_loss: 0.0146 - val_acc: 1.0000\n",
      "Epoch 82/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 2.0543e-04 - acc: 1.0000 - val_loss: 0.0145 - val_acc: 1.0000\n",
      "Epoch 83/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.9924e-04 - acc: 1.0000 - val_loss: 0.0144 - val_acc: 1.0000\n",
      "Epoch 84/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.9348e-04 - acc: 1.0000 - val_loss: 0.0141 - val_acc: 1.0000\n",
      "Epoch 85/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.8733e-04 - acc: 1.0000 - val_loss: 0.0140 - val_acc: 1.0000\n",
      "Epoch 86/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.8185e-04 - acc: 1.0000 - val_loss: 0.0138 - val_acc: 1.0000\n",
      "Epoch 87/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.7657e-04 - acc: 1.0000 - val_loss: 0.0137 - val_acc: 1.0000\n",
      "Epoch 88/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.7157e-04 - acc: 1.0000 - val_loss: 0.0136 - val_acc: 1.0000\n",
      "Epoch 89/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.6679e-04 - acc: 1.0000 - val_loss: 0.0133 - val_acc: 1.0000\n",
      "Epoch 90/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.6195e-04 - acc: 1.0000 - val_loss: 0.0133 - val_acc: 1.0000\n",
      "Epoch 91/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.5736e-04 - acc: 1.0000 - val_loss: 0.0131 - val_acc: 1.0000\n",
      "Epoch 92/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.5312e-04 - acc: 1.0000 - val_loss: 0.0129 - val_acc: 1.0000\n",
      "Epoch 93/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.4882e-04 - acc: 1.0000 - val_loss: 0.0128 - val_acc: 1.0000\n",
      "Epoch 94/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.4477e-04 - acc: 1.0000 - val_loss: 0.0127 - val_acc: 1.0000\n",
      "Epoch 95/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.4092e-04 - acc: 1.0000 - val_loss: 0.0125 - val_acc: 1.0000\n",
      "Epoch 96/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.3703e-04 - acc: 1.0000 - val_loss: 0.0124 - val_acc: 1.0000\n",
      "Epoch 97/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.3348e-04 - acc: 1.0000 - val_loss: 0.0123 - val_acc: 1.0000\n",
      "Epoch 98/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.3018e-04 - acc: 1.0000 - val_loss: 0.0122 - val_acc: 1.0000\n",
      "Epoch 99/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.2648e-04 - acc: 1.0000 - val_loss: 0.0121 - val_acc: 1.0000\n",
      "Epoch 100/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.2344e-04 - acc: 1.0000 - val_loss: 0.0119 - val_acc: 1.0000\n",
      "Epoch 101/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.2012e-04 - acc: 1.0000 - val_loss: 0.0119 - val_acc: 1.0000\n",
      "Epoch 102/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.1716e-04 - acc: 1.0000 - val_loss: 0.0117 - val_acc: 1.0000\n",
      "Epoch 103/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.1402e-04 - acc: 1.0000 - val_loss: 0.0116 - val_acc: 1.0000\n",
      "Epoch 104/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.1119e-04 - acc: 1.0000 - val_loss: 0.0114 - val_acc: 1.0000\n",
      "Epoch 105/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.0840e-04 - acc: 1.0000 - val_loss: 0.0114 - val_acc: 1.0000\n",
      "Epoch 106/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.0568e-04 - acc: 1.0000 - val_loss: 0.0113 - val_acc: 1.0000\n",
      "Epoch 107/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.0309e-04 - acc: 1.0000 - val_loss: 0.0111 - val_acc: 1.0000\n",
      "Epoch 108/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.0046e-04 - acc: 1.0000 - val_loss: 0.0110 - val_acc: 1.0000\n",
      "Epoch 109/200\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 9.8039e-05 - acc: 1.0000 - val_loss: 0.0110 - val_acc: 1.0000\n",
      "Epoch 110/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 9.5754e-05 - acc: 1.0000 - val_loss: 0.0108 - val_acc: 1.0000\n",
      "Epoch 111/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 9.3465e-05 - acc: 1.0000 - val_loss: 0.0107 - val_acc: 1.0000\n",
      "Epoch 112/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 9.1126e-05 - acc: 1.0000 - val_loss: 0.0106 - val_acc: 1.0000\n",
      "Epoch 113/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 8.8965e-05 - acc: 1.0000 - val_loss: 0.0105 - val_acc: 1.0000\n",
      "Epoch 114/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 8.6991e-05 - acc: 1.0000 - val_loss: 0.0104 - val_acc: 1.0000\n",
      "Epoch 115/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 8.4869e-05 - acc: 1.0000 - val_loss: 0.0103 - val_acc: 1.0000\n",
      "Epoch 116/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 8.2915e-05 - acc: 1.0000 - val_loss: 0.0102 - val_acc: 1.0000\n",
      "Epoch 117/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 8.1039e-05 - acc: 1.0000 - val_loss: 0.0101 - val_acc: 1.0000\n",
      "Epoch 118/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 7.9088e-05 - acc: 1.0000 - val_loss: 0.0100 - val_acc: 1.0000\n",
      "Epoch 119/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 7.7343e-05 - acc: 1.0000 - val_loss: 0.0099 - val_acc: 1.0000\n",
      "Epoch 120/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149/149 [==============================] - 0s 1ms/step - loss: 7.5657e-05 - acc: 1.0000 - val_loss: 0.0098 - val_acc: 1.0000\n",
      "Epoch 121/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 7.3925e-05 - acc: 1.0000 - val_loss: 0.0097 - val_acc: 1.0000\n",
      "Epoch 122/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 7.2172e-05 - acc: 1.0000 - val_loss: 0.0097 - val_acc: 1.0000\n",
      "Epoch 123/200\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 7.0588e-05 - acc: 1.0000 - val_loss: 0.0096 - val_acc: 1.0000\n",
      "Epoch 124/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 6.9014e-05 - acc: 1.0000 - val_loss: 0.0095 - val_acc: 1.0000\n",
      "Epoch 125/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 6.7569e-05 - acc: 1.0000 - val_loss: 0.0094 - val_acc: 1.0000\n",
      "Epoch 126/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 6.6046e-05 - acc: 1.0000 - val_loss: 0.0093 - val_acc: 1.0000\n",
      "Epoch 127/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 6.4679e-05 - acc: 1.0000 - val_loss: 0.0093 - val_acc: 1.0000\n",
      "Epoch 128/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 6.3224e-05 - acc: 1.0000 - val_loss: 0.0092 - val_acc: 1.0000\n",
      "Epoch 129/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 6.1852e-05 - acc: 1.0000 - val_loss: 0.0091 - val_acc: 1.0000\n",
      "Epoch 130/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 6.0587e-05 - acc: 1.0000 - val_loss: 0.0090 - val_acc: 1.0000\n",
      "Epoch 131/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 5.9182e-05 - acc: 1.0000 - val_loss: 0.0090 - val_acc: 1.0000\n",
      "Epoch 132/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 5.7970e-05 - acc: 1.0000 - val_loss: 0.0089 - val_acc: 1.0000\n",
      "Epoch 133/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 5.6790e-05 - acc: 1.0000 - val_loss: 0.0089 - val_acc: 1.0000\n",
      "Epoch 134/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 5.5577e-05 - acc: 1.0000 - val_loss: 0.0087 - val_acc: 1.0000\n",
      "Epoch 135/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 5.4366e-05 - acc: 1.0000 - val_loss: 0.0087 - val_acc: 1.0000\n",
      "Epoch 136/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 5.3216e-05 - acc: 1.0000 - val_loss: 0.0086 - val_acc: 1.0000\n",
      "Epoch 137/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 5.2124e-05 - acc: 1.0000 - val_loss: 0.0085 - val_acc: 1.0000\n",
      "Epoch 138/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 5.1051e-05 - acc: 1.0000 - val_loss: 0.0085 - val_acc: 1.0000\n",
      "Epoch 139/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 4.9976e-05 - acc: 1.0000 - val_loss: 0.0084 - val_acc: 1.0000\n",
      "Epoch 140/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 4.8933e-05 - acc: 1.0000 - val_loss: 0.0083 - val_acc: 1.0000\n",
      "Epoch 141/200\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 4.7932e-05 - acc: 1.0000 - val_loss: 0.0083 - val_acc: 1.0000\n",
      "Epoch 142/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 4.6992e-05 - acc: 1.0000 - val_loss: 0.0082 - val_acc: 1.0000\n",
      "Epoch 143/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 4.5999e-05 - acc: 1.0000 - val_loss: 0.0081 - val_acc: 1.0000\n",
      "Epoch 144/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 4.5053e-05 - acc: 1.0000 - val_loss: 0.0080 - val_acc: 1.0000\n",
      "Epoch 145/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 4.4134e-05 - acc: 1.0000 - val_loss: 0.0080 - val_acc: 1.0000\n",
      "Epoch 146/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 4.3253e-05 - acc: 1.0000 - val_loss: 0.0079 - val_acc: 1.0000\n",
      "Epoch 147/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 4.2394e-05 - acc: 1.0000 - val_loss: 0.0079 - val_acc: 1.0000\n",
      "Epoch 148/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 4.1568e-05 - acc: 1.0000 - val_loss: 0.0078 - val_acc: 1.0000\n",
      "Epoch 149/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 4.0757e-05 - acc: 1.0000 - val_loss: 0.0078 - val_acc: 1.0000\n",
      "Epoch 150/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 3.9913e-05 - acc: 1.0000 - val_loss: 0.0077 - val_acc: 1.0000\n",
      "Epoch 151/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 3.9140e-05 - acc: 1.0000 - val_loss: 0.0076 - val_acc: 1.0000\n",
      "Epoch 152/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 3.8426e-05 - acc: 1.0000 - val_loss: 0.0076 - val_acc: 1.0000\n",
      "Epoch 153/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 3.7617e-05 - acc: 1.0000 - val_loss: 0.0075 - val_acc: 1.0000\n",
      "Epoch 154/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 3.6875e-05 - acc: 1.0000 - val_loss: 0.0074 - val_acc: 1.0000\n",
      "Epoch 155/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 3.6180e-05 - acc: 1.0000 - val_loss: 0.0074 - val_acc: 1.0000\n",
      "Epoch 156/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 3.5466e-05 - acc: 1.0000 - val_loss: 0.0074 - val_acc: 1.0000\n",
      "Epoch 157/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 3.4783e-05 - acc: 1.0000 - val_loss: 0.0073 - val_acc: 1.0000\n",
      "Epoch 158/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 3.4121e-05 - acc: 1.0000 - val_loss: 0.0073 - val_acc: 1.0000\n",
      "Epoch 159/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 3.3457e-05 - acc: 1.0000 - val_loss: 0.0072 - val_acc: 1.0000\n",
      "Epoch 160/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 3.2809e-05 - acc: 1.0000 - val_loss: 0.0071 - val_acc: 1.0000\n",
      "Epoch 161/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 3.2201e-05 - acc: 1.0000 - val_loss: 0.0071 - val_acc: 1.0000\n",
      "Epoch 162/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 3.1586e-05 - acc: 1.0000 - val_loss: 0.0070 - val_acc: 1.0000\n",
      "Epoch 163/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 3.0983e-05 - acc: 1.0000 - val_loss: 0.0070 - val_acc: 1.0000\n",
      "Epoch 164/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 3.0412e-05 - acc: 1.0000 - val_loss: 0.0069 - val_acc: 1.0000\n",
      "Epoch 165/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 2.9833e-05 - acc: 1.0000 - val_loss: 0.0069 - val_acc: 1.0000\n",
      "Epoch 166/200\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 2.9284e-05 - acc: 1.0000 - val_loss: 0.0068 - val_acc: 1.0000\n",
      "Epoch 167/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 2.8754e-05 - acc: 1.0000 - val_loss: 0.0068 - val_acc: 1.0000\n",
      "Epoch 168/200\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 2.8207e-05 - acc: 1.0000 - val_loss: 0.0067 - val_acc: 1.0000\n",
      "Epoch 169/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 2.7702e-05 - acc: 1.0000 - val_loss: 0.0067 - val_acc: 1.0000\n",
      "Epoch 170/200\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 2.7171e-05 - acc: 1.0000 - val_loss: 0.0066 - val_acc: 1.0000\n",
      "Epoch 171/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 2.6693e-05 - acc: 1.0000 - val_loss: 0.0065 - val_acc: 1.0000\n",
      "Epoch 172/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 2.6202e-05 - acc: 1.0000 - val_loss: 0.0065 - val_acc: 1.0000\n",
      "Epoch 173/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 2.5721e-05 - acc: 1.0000 - val_loss: 0.0065 - val_acc: 1.0000\n",
      "Epoch 174/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 2.5246e-05 - acc: 1.0000 - val_loss: 0.0064 - val_acc: 1.0000\n",
      "Epoch 175/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 2.4813e-05 - acc: 1.0000 - val_loss: 0.0064 - val_acc: 1.0000\n",
      "Epoch 176/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 2.4356e-05 - acc: 1.0000 - val_loss: 0.0063 - val_acc: 1.0000\n",
      "Epoch 177/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 2.3914e-05 - acc: 1.0000 - val_loss: 0.0063 - val_acc: 1.0000\n",
      "Epoch 178/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 2.3496e-05 - acc: 1.0000 - val_loss: 0.0062 - val_acc: 1.0000\n",
      "Epoch 179/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149/149 [==============================] - 0s 1ms/step - loss: 2.3057e-05 - acc: 1.0000 - val_loss: 0.0062 - val_acc: 1.0000\n",
      "Epoch 180/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 2.2654e-05 - acc: 1.0000 - val_loss: 0.0061 - val_acc: 1.0000\n",
      "Epoch 181/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 2.2258e-05 - acc: 1.0000 - val_loss: 0.0061 - val_acc: 1.0000\n",
      "Epoch 182/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 2.1870e-05 - acc: 1.0000 - val_loss: 0.0061 - val_acc: 1.0000\n",
      "Epoch 183/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 2.1500e-05 - acc: 1.0000 - val_loss: 0.0060 - val_acc: 1.0000\n",
      "Epoch 184/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 2.1086e-05 - acc: 1.0000 - val_loss: 0.0060 - val_acc: 1.0000\n",
      "Epoch 185/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 2.0734e-05 - acc: 1.0000 - val_loss: 0.0059 - val_acc: 1.0000\n",
      "Epoch 186/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 2.0353e-05 - acc: 1.0000 - val_loss: 0.0059 - val_acc: 1.0000\n",
      "Epoch 187/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 2.0017e-05 - acc: 1.0000 - val_loss: 0.0059 - val_acc: 1.0000\n",
      "Epoch 188/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.9646e-05 - acc: 1.0000 - val_loss: 0.0058 - val_acc: 1.0000\n",
      "Epoch 189/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.9309e-05 - acc: 1.0000 - val_loss: 0.0058 - val_acc: 1.0000\n",
      "Epoch 190/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.9004e-05 - acc: 1.0000 - val_loss: 0.0057 - val_acc: 1.0000\n",
      "Epoch 191/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.8638e-05 - acc: 1.0000 - val_loss: 0.0057 - val_acc: 1.0000\n",
      "Epoch 192/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.8319e-05 - acc: 1.0000 - val_loss: 0.0057 - val_acc: 1.0000\n",
      "Epoch 193/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.8017e-05 - acc: 1.0000 - val_loss: 0.0056 - val_acc: 1.0000\n",
      "Epoch 194/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.7678e-05 - acc: 1.0000 - val_loss: 0.0056 - val_acc: 1.0000\n",
      "Epoch 195/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.7397e-05 - acc: 1.0000 - val_loss: 0.0056 - val_acc: 1.0000\n",
      "Epoch 196/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.7096e-05 - acc: 1.0000 - val_loss: 0.0055 - val_acc: 1.0000\n",
      "Epoch 197/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.6795e-05 - acc: 1.0000 - val_loss: 0.0055 - val_acc: 1.0000\n",
      "Epoch 198/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.6524e-05 - acc: 1.0000 - val_loss: 0.0054 - val_acc: 1.0000\n",
      "Epoch 199/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.6234e-05 - acc: 1.0000 - val_loss: 0.0054 - val_acc: 1.0000\n",
      "Epoch 200/200\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.5973e-05 - acc: 1.0000 - val_loss: 0.0053 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20386d66588>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "model  = Sequential()\n",
    "model.add(Dense(32,input_dim = x_train_scaled.shape[1],activation=\"relu\"))\n",
    "model.add(Dense(32,activation=\"relu\"))\n",
    "model.add(Dense(1,activation = \"sigmoid\"))\n",
    "\n",
    "model.compile(optimizer = \"Adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(x_train_scaled,y_train, \n",
    "validation_data = (x_val_scaled,y_val),epochs=200, batch_size=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(model.history.history['loss'])\n",
    "plt.plot(model.history.history['val_loss'])\n",
    "plt.title(\"Model's Training & Validation loss across epochs\")\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(model.history.history['acc'])\n",
    "plt.plot(model.history.history['val_acc'])\n",
    "plt.title(\"Model's Training & Validation Accuracy across epochs\")\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 149 samples, validate on 17 samples\n",
      "Epoch 1/500\n",
      "149/149 [==============================] - 1s 10ms/step - loss: 0.6433 - acc: 0.5705 - val_loss: 0.6488 - val_acc: 0.5294\n",
      "Epoch 2/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.6098 - acc: 0.6107 - val_loss: 0.6184 - val_acc: 0.7059\n",
      "Epoch 3/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.5816 - acc: 0.6913 - val_loss: 0.5877 - val_acc: 0.7647\n",
      "Epoch 4/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.5507 - acc: 0.7718 - val_loss: 0.5636 - val_acc: 0.7647\n",
      "Epoch 5/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.5190 - acc: 0.8188 - val_loss: 0.5381 - val_acc: 0.8235\n",
      "Epoch 6/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.4858 - acc: 0.8188 - val_loss: 0.5055 - val_acc: 0.8235\n",
      "Epoch 7/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.4492 - acc: 0.8456 - val_loss: 0.4720 - val_acc: 0.8824\n",
      "Epoch 8/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4135 - acc: 0.8725 - val_loss: 0.4428 - val_acc: 0.8824\n",
      "Epoch 9/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.3783 - acc: 0.9060 - val_loss: 0.4158 - val_acc: 0.8824\n",
      "Epoch 10/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.3424 - acc: 0.9128 - val_loss: 0.3868 - val_acc: 0.8824\n",
      "Epoch 11/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.3113 - acc: 0.9195 - val_loss: 0.3650 - val_acc: 0.9412\n",
      "Epoch 12/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.2814 - acc: 0.9329 - val_loss: 0.3341 - val_acc: 0.9412\n",
      "Epoch 13/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.2562 - acc: 0.9396 - val_loss: 0.3125 - val_acc: 0.9412\n",
      "Epoch 14/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.2348 - acc: 0.9463 - val_loss: 0.2937 - val_acc: 0.9412\n",
      "Epoch 15/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.2143 - acc: 0.9530 - val_loss: 0.2791 - val_acc: 0.9412\n",
      "Epoch 16/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.1973 - acc: 0.9530 - val_loss: 0.2584 - val_acc: 0.9412\n",
      "Epoch 17/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.1802 - acc: 0.9664 - val_loss: 0.2430 - val_acc: 0.9412\n",
      "Epoch 18/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.1668 - acc: 0.9799 - val_loss: 0.2351 - val_acc: 0.9412\n",
      "Epoch 19/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.1543 - acc: 0.9799 - val_loss: 0.2281 - val_acc: 0.9412\n",
      "Epoch 20/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.1435 - acc: 0.9799 - val_loss: 0.2222 - val_acc: 0.9412\n",
      "Epoch 21/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.1331 - acc: 0.9799 - val_loss: 0.2169 - val_acc: 0.9412\n",
      "Epoch 22/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.1244 - acc: 0.9866 - val_loss: 0.2149 - val_acc: 0.9412\n",
      "Epoch 23/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.1155 - acc: 0.9866 - val_loss: 0.2063 - val_acc: 0.9412\n",
      "Epoch 24/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.1075 - acc: 0.9866 - val_loss: 0.2074 - val_acc: 0.9412\n",
      "Epoch 25/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0986 - acc: 0.9866 - val_loss: 0.2076 - val_acc: 0.9412\n",
      "Epoch 26/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0907 - acc: 0.9933 - val_loss: 0.2055 - val_acc: 0.9412\n",
      "Epoch 27/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0838 - acc: 0.9933 - val_loss: 0.2013 - val_acc: 0.9412\n",
      "Epoch 28/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0756 - acc: 1.0000 - val_loss: 0.1917 - val_acc: 0.9412\n",
      "Epoch 29/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0687 - acc: 1.0000 - val_loss: 0.1850 - val_acc: 0.9412\n",
      "Epoch 30/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0632 - acc: 1.0000 - val_loss: 0.1844 - val_acc: 0.9412\n",
      "Epoch 31/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.0582 - acc: 1.0000 - val_loss: 0.1770 - val_acc: 0.9412\n",
      "Epoch 32/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.0540 - acc: 1.0000 - val_loss: 0.1723 - val_acc: 0.9412\n",
      "Epoch 33/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0499 - acc: 1.0000 - val_loss: 0.1655 - val_acc: 0.9412\n",
      "Epoch 34/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.0465 - acc: 1.0000 - val_loss: 0.1604 - val_acc: 0.9412\n",
      "Epoch 35/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.0435 - acc: 1.0000 - val_loss: 0.1591 - val_acc: 0.9412\n",
      "Epoch 36/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.0403 - acc: 1.0000 - val_loss: 0.1516 - val_acc: 0.9412\n",
      "Epoch 37/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0375 - acc: 1.0000 - val_loss: 0.1429 - val_acc: 0.9412\n",
      "Epoch 38/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0349 - acc: 1.0000 - val_loss: 0.1388 - val_acc: 0.9412\n",
      "Epoch 39/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0323 - acc: 1.0000 - val_loss: 0.1343 - val_acc: 0.9412\n",
      "Epoch 40/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.0298 - acc: 1.0000 - val_loss: 0.1295 - val_acc: 0.9412\n",
      "Epoch 41/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0275 - acc: 1.0000 - val_loss: 0.1240 - val_acc: 0.9412\n",
      "Epoch 42/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0253 - acc: 1.0000 - val_loss: 0.1214 - val_acc: 0.9412\n",
      "Epoch 43/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0233 - acc: 1.0000 - val_loss: 0.1142 - val_acc: 0.9412\n",
      "Epoch 44/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0214 - acc: 1.0000 - val_loss: 0.1064 - val_acc: 0.9412\n",
      "Epoch 45/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0196 - acc: 1.0000 - val_loss: 0.1025 - val_acc: 0.9412\n",
      "Epoch 46/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0181 - acc: 1.0000 - val_loss: 0.0971 - val_acc: 0.9412\n",
      "Epoch 47/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0166 - acc: 1.0000 - val_loss: 0.0933 - val_acc: 0.9412\n",
      "Epoch 48/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.0155 - acc: 1.0000 - val_loss: 0.0891 - val_acc: 0.9412\n",
      "Epoch 49/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0144 - acc: 1.0000 - val_loss: 0.0842 - val_acc: 0.9412\n",
      "Epoch 50/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0134 - acc: 1.0000 - val_loss: 0.0789 - val_acc: 0.9412\n",
      "Epoch 51/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.0126 - acc: 1.0000 - val_loss: 0.0751 - val_acc: 0.9412\n",
      "Epoch 52/500\n",
      "149/149 [==============================] - 0s 899us/step - loss: 0.0118 - acc: 1.0000 - val_loss: 0.0708 - val_acc: 0.9412\n",
      "Epoch 53/500\n",
      "149/149 [==============================] - 0s 916us/step - loss: 0.0112 - acc: 1.0000 - val_loss: 0.0667 - val_acc: 0.9412\n",
      "Epoch 54/500\n",
      "149/149 [==============================] - 0s 938us/step - loss: 0.0105 - acc: 1.0000 - val_loss: 0.0634 - val_acc: 0.9412\n",
      "Epoch 55/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.0100 - acc: 1.0000 - val_loss: 0.0602 - val_acc: 0.9412\n",
      "Epoch 56/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0094 - acc: 1.0000 - val_loss: 0.0574 - val_acc: 0.9412\n",
      "Epoch 57/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.0090 - acc: 1.0000 - val_loss: 0.0543 - val_acc: 0.9412\n",
      "Epoch 58/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.0086 - acc: 1.0000 - val_loss: 0.0514 - val_acc: 0.9412\n",
      "Epoch 59/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.0082 - acc: 1.0000 - val_loss: 0.0491 - val_acc: 1.0000\n",
      "Epoch 60/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.0078 - acc: 1.0000 - val_loss: 0.0476 - val_acc: 1.0000\n",
      "Epoch 61/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0075 - acc: 1.0000 - val_loss: 0.0453 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0072 - acc: 1.0000 - val_loss: 0.0431 - val_acc: 1.0000\n",
      "Epoch 63/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.0069 - acc: 1.0000 - val_loss: 0.0409 - val_acc: 1.0000\n",
      "Epoch 64/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0066 - acc: 1.0000 - val_loss: 0.0396 - val_acc: 1.0000\n",
      "Epoch 65/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0055 - acc: 1.0000 - val_loss: 0.0386 - val_acc: 1.0000\n",
      "Epoch 66/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.0372 - val_acc: 1.0000\n",
      "Epoch 67/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.0361 - val_acc: 1.0000\n",
      "Epoch 68/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.0351 - val_acc: 1.0000\n",
      "Epoch 69/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.0343 - val_acc: 1.0000\n",
      "Epoch 70/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0328 - val_acc: 1.0000\n",
      "Epoch 71/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0321 - val_acc: 1.0000\n",
      "Epoch 72/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0315 - val_acc: 1.0000\n",
      "Epoch 73/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0301 - val_acc: 1.0000\n",
      "Epoch 74/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0301 - val_acc: 1.0000\n",
      "Epoch 75/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0292 - val_acc: 1.0000\n",
      "Epoch 76/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0284 - val_acc: 1.0000\n",
      "Epoch 77/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0277 - val_acc: 1.0000\n",
      "Epoch 78/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0272 - val_acc: 1.0000\n",
      "Epoch 79/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0261 - val_acc: 1.0000\n",
      "Epoch 80/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0256 - val_acc: 1.0000\n",
      "Epoch 81/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0251 - val_acc: 1.0000\n",
      "Epoch 82/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0244 - val_acc: 1.0000\n",
      "Epoch 83/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0241 - val_acc: 1.0000\n",
      "Epoch 84/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0237 - val_acc: 1.0000\n",
      "Epoch 85/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0229 - val_acc: 1.0000\n",
      "Epoch 86/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0225 - val_acc: 1.0000\n",
      "Epoch 87/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0219 - val_acc: 1.0000\n",
      "Epoch 88/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0215 - val_acc: 1.0000\n",
      "Epoch 89/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0212 - val_acc: 1.0000\n",
      "Epoch 90/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0207 - val_acc: 1.0000\n",
      "Epoch 91/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0201 - val_acc: 1.0000\n",
      "Epoch 92/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0199 - val_acc: 1.0000\n",
      "Epoch 93/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0196 - val_acc: 1.0000\n",
      "Epoch 94/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0190 - val_acc: 1.0000\n",
      "Epoch 95/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0187 - val_acc: 1.0000\n",
      "Epoch 96/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0183 - val_acc: 1.0000\n",
      "Epoch 97/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0181 - val_acc: 1.0000\n",
      "Epoch 98/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0176 - val_acc: 1.0000\n",
      "Epoch 99/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0172 - val_acc: 1.0000\n",
      "Epoch 100/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0168 - val_acc: 1.0000\n",
      "Epoch 101/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 9.8745e-04 - acc: 1.0000 - val_loss: 0.0168 - val_acc: 1.0000\n",
      "Epoch 102/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 9.5665e-04 - acc: 1.0000 - val_loss: 0.0163 - val_acc: 1.0000\n",
      "Epoch 103/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 9.2726e-04 - acc: 1.0000 - val_loss: 0.0161 - val_acc: 1.0000\n",
      "Epoch 104/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 8.9912e-04 - acc: 1.0000 - val_loss: 0.0156 - val_acc: 1.0000\n",
      "Epoch 105/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 8.7222e-04 - acc: 1.0000 - val_loss: 0.0155 - val_acc: 1.0000\n",
      "Epoch 106/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 8.4719e-04 - acc: 1.0000 - val_loss: 0.0152 - val_acc: 1.0000\n",
      "Epoch 107/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 8.2180e-04 - acc: 1.0000 - val_loss: 0.0149 - val_acc: 1.0000\n",
      "Epoch 108/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 7.9835e-04 - acc: 1.0000 - val_loss: 0.0146 - val_acc: 1.0000\n",
      "Epoch 109/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 7.7368e-04 - acc: 1.0000 - val_loss: 0.0144 - val_acc: 1.0000\n",
      "Epoch 110/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 7.5292e-04 - acc: 1.0000 - val_loss: 0.0142 - val_acc: 1.0000\n",
      "Epoch 111/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 7.3223e-04 - acc: 1.0000 - val_loss: 0.0138 - val_acc: 1.0000\n",
      "Epoch 112/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 7.1298e-04 - acc: 1.0000 - val_loss: 0.0138 - val_acc: 1.0000\n",
      "Epoch 113/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 6.9096e-04 - acc: 1.0000 - val_loss: 0.0135 - val_acc: 1.0000\n",
      "Epoch 114/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 6.7273e-04 - acc: 1.0000 - val_loss: 0.0132 - val_acc: 1.0000\n",
      "Epoch 115/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 6.5398e-04 - acc: 1.0000 - val_loss: 0.0130 - val_acc: 1.0000\n",
      "Epoch 116/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 6.3580e-04 - acc: 1.0000 - val_loss: 0.0129 - val_acc: 1.0000\n",
      "Epoch 117/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 6.2048e-04 - acc: 1.0000 - val_loss: 0.0126 - val_acc: 1.0000\n",
      "Epoch 118/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 6.0319e-04 - acc: 1.0000 - val_loss: 0.0125 - val_acc: 1.0000\n",
      "Epoch 119/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 5.8760e-04 - acc: 1.0000 - val_loss: 0.0123 - val_acc: 1.0000\n",
      "Epoch 120/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 5.7253e-04 - acc: 1.0000 - val_loss: 0.0121 - val_acc: 1.0000\n",
      "Epoch 121/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 5.5804e-04 - acc: 1.0000 - val_loss: 0.0119 - val_acc: 1.0000\n",
      "Epoch 122/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149/149 [==============================] - 0s 1ms/step - loss: 5.4392e-04 - acc: 1.0000 - val_loss: 0.0117 - val_acc: 1.0000\n",
      "Epoch 123/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 5.3016e-04 - acc: 1.0000 - val_loss: 0.0116 - val_acc: 1.0000\n",
      "Epoch 124/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 5.1699e-04 - acc: 1.0000 - val_loss: 0.0114 - val_acc: 1.0000\n",
      "Epoch 125/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 5.0377e-04 - acc: 1.0000 - val_loss: 0.0113 - val_acc: 1.0000\n",
      "Epoch 126/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 4.9206e-04 - acc: 1.0000 - val_loss: 0.0111 - val_acc: 1.0000\n",
      "Epoch 127/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 4.7928e-04 - acc: 1.0000 - val_loss: 0.0110 - val_acc: 1.0000\n",
      "Epoch 128/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 4.6835e-04 - acc: 1.0000 - val_loss: 0.0107 - val_acc: 1.0000\n",
      "Epoch 129/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 4.5629e-04 - acc: 1.0000 - val_loss: 0.0106 - val_acc: 1.0000\n",
      "Epoch 130/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 4.4532e-04 - acc: 1.0000 - val_loss: 0.0106 - val_acc: 1.0000\n",
      "Epoch 131/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 4.3505e-04 - acc: 1.0000 - val_loss: 0.0103 - val_acc: 1.0000\n",
      "Epoch 132/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 4.2445e-04 - acc: 1.0000 - val_loss: 0.0102 - val_acc: 1.0000\n",
      "Epoch 133/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 4.1474e-04 - acc: 1.0000 - val_loss: 0.0100 - val_acc: 1.0000\n",
      "Epoch 134/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 4.0492e-04 - acc: 1.0000 - val_loss: 0.0100 - val_acc: 1.0000\n",
      "Epoch 135/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 3.9539e-04 - acc: 1.0000 - val_loss: 0.0098 - val_acc: 1.0000\n",
      "Epoch 136/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 3.8631e-04 - acc: 1.0000 - val_loss: 0.0097 - val_acc: 1.0000\n",
      "Epoch 137/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 3.7755e-04 - acc: 1.0000 - val_loss: 0.0095 - val_acc: 1.0000\n",
      "Epoch 138/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 3.6901e-04 - acc: 1.0000 - val_loss: 0.0094 - val_acc: 1.0000\n",
      "Epoch 139/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 3.6037e-04 - acc: 1.0000 - val_loss: 0.0092 - val_acc: 1.0000\n",
      "Epoch 140/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 3.5230e-04 - acc: 1.0000 - val_loss: 0.0091 - val_acc: 1.0000\n",
      "Epoch 141/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 3.4427e-04 - acc: 1.0000 - val_loss: 0.0090 - val_acc: 1.0000\n",
      "Epoch 142/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 3.3662e-04 - acc: 1.0000 - val_loss: 0.0089 - val_acc: 1.0000\n",
      "Epoch 143/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 3.2932e-04 - acc: 1.0000 - val_loss: 0.0088 - val_acc: 1.0000\n",
      "Epoch 144/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 3.2182e-04 - acc: 1.0000 - val_loss: 0.0087 - val_acc: 1.0000\n",
      "Epoch 145/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 3.1472e-04 - acc: 1.0000 - val_loss: 0.0086 - val_acc: 1.0000\n",
      "Epoch 146/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 3.0786e-04 - acc: 1.0000 - val_loss: 0.0085 - val_acc: 1.0000\n",
      "Epoch 147/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 3.0092e-04 - acc: 1.0000 - val_loss: 0.0084 - val_acc: 1.0000\n",
      "Epoch 148/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 2.9457e-04 - acc: 1.0000 - val_loss: 0.0083 - val_acc: 1.0000\n",
      "Epoch 149/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 2.8804e-04 - acc: 1.0000 - val_loss: 0.0082 - val_acc: 1.0000\n",
      "Epoch 150/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 2.8172e-04 - acc: 1.0000 - val_loss: 0.0081 - val_acc: 1.0000\n",
      "Epoch 151/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 2.7554e-04 - acc: 1.0000 - val_loss: 0.0080 - val_acc: 1.0000\n",
      "Epoch 152/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 2.6954e-04 - acc: 1.0000 - val_loss: 0.0079 - val_acc: 1.0000\n",
      "Epoch 153/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 2.6416e-04 - acc: 1.0000 - val_loss: 0.0078 - val_acc: 1.0000\n",
      "Epoch 154/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 2.5871e-04 - acc: 1.0000 - val_loss: 0.0077 - val_acc: 1.0000\n",
      "Epoch 155/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 2.5300e-04 - acc: 1.0000 - val_loss: 0.0077 - val_acc: 1.0000\n",
      "Epoch 156/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 2.4768e-04 - acc: 1.0000 - val_loss: 0.0076 - val_acc: 1.0000\n",
      "Epoch 157/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 2.4253e-04 - acc: 1.0000 - val_loss: 0.0075 - val_acc: 1.0000\n",
      "Epoch 158/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 2.3763e-04 - acc: 1.0000 - val_loss: 0.0074 - val_acc: 1.0000\n",
      "Epoch 159/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 2.3271e-04 - acc: 1.0000 - val_loss: 0.0074 - val_acc: 1.0000\n",
      "Epoch 160/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 2.2766e-04 - acc: 1.0000 - val_loss: 0.0073 - val_acc: 1.0000\n",
      "Epoch 161/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 2.2301e-04 - acc: 1.0000 - val_loss: 0.0072 - val_acc: 1.0000\n",
      "Epoch 162/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 2.1840e-04 - acc: 1.0000 - val_loss: 0.0071 - val_acc: 1.0000\n",
      "Epoch 163/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 2.1412e-04 - acc: 1.0000 - val_loss: 0.0070 - val_acc: 1.0000\n",
      "Epoch 164/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 2.0973e-04 - acc: 1.0000 - val_loss: 0.0069 - val_acc: 1.0000\n",
      "Epoch 165/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 2.0568e-04 - acc: 1.0000 - val_loss: 0.0069 - val_acc: 1.0000\n",
      "Epoch 166/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 2.0135e-04 - acc: 1.0000 - val_loss: 0.0068 - val_acc: 1.0000\n",
      "Epoch 167/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.9723e-04 - acc: 1.0000 - val_loss: 0.0067 - val_acc: 1.0000\n",
      "Epoch 168/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.9332e-04 - acc: 1.0000 - val_loss: 0.0066 - val_acc: 1.0000\n",
      "Epoch 169/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.8959e-04 - acc: 1.0000 - val_loss: 0.0066 - val_acc: 1.0000\n",
      "Epoch 170/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.8582e-04 - acc: 1.0000 - val_loss: 0.0065 - val_acc: 1.0000\n",
      "Epoch 171/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.8230e-04 - acc: 1.0000 - val_loss: 0.0064 - val_acc: 1.0000\n",
      "Epoch 172/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.7857e-04 - acc: 1.0000 - val_loss: 0.0064 - val_acc: 1.0000\n",
      "Epoch 173/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 1.7494e-04 - acc: 1.0000 - val_loss: 0.0063 - val_acc: 1.0000\n",
      "Epoch 174/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.7173e-04 - acc: 1.0000 - val_loss: 0.0062 - val_acc: 1.0000\n",
      "Epoch 175/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.6834e-04 - acc: 1.0000 - val_loss: 0.0062 - val_acc: 1.0000\n",
      "Epoch 176/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.6511e-04 - acc: 1.0000 - val_loss: 0.0061 - val_acc: 1.0000\n",
      "Epoch 177/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.6184e-04 - acc: 1.0000 - val_loss: 0.0061 - val_acc: 1.0000\n",
      "Epoch 178/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.5885e-04 - acc: 1.0000 - val_loss: 0.0060 - val_acc: 1.0000\n",
      "Epoch 179/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.5573e-04 - acc: 1.0000 - val_loss: 0.0059 - val_acc: 1.0000\n",
      "Epoch 180/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.5290e-04 - acc: 1.0000 - val_loss: 0.0059 - val_acc: 1.0000\n",
      "Epoch 181/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149/149 [==============================] - 0s 1ms/step - loss: 1.4981e-04 - acc: 1.0000 - val_loss: 0.0058 - val_acc: 1.0000\n",
      "Epoch 182/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 1.4705e-04 - acc: 1.0000 - val_loss: 0.0057 - val_acc: 1.0000\n",
      "Epoch 183/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.4417e-04 - acc: 1.0000 - val_loss: 0.0057 - val_acc: 1.0000\n",
      "Epoch 184/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.4163e-04 - acc: 1.0000 - val_loss: 0.0056 - val_acc: 1.0000\n",
      "Epoch 185/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.3890e-04 - acc: 1.0000 - val_loss: 0.0056 - val_acc: 1.0000\n",
      "Epoch 186/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.3626e-04 - acc: 1.0000 - val_loss: 0.0055 - val_acc: 1.0000\n",
      "Epoch 187/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 1.3394e-04 - acc: 1.0000 - val_loss: 0.0054 - val_acc: 1.0000\n",
      "Epoch 188/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.3125e-04 - acc: 1.0000 - val_loss: 0.0054 - val_acc: 1.0000\n",
      "Epoch 189/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.2890e-04 - acc: 1.0000 - val_loss: 0.0054 - val_acc: 1.0000\n",
      "Epoch 190/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.2652e-04 - acc: 1.0000 - val_loss: 0.0053 - val_acc: 1.0000\n",
      "Epoch 191/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.2417e-04 - acc: 1.0000 - val_loss: 0.0053 - val_acc: 1.0000\n",
      "Epoch 192/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.2182e-04 - acc: 1.0000 - val_loss: 0.0052 - val_acc: 1.0000\n",
      "Epoch 193/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.1970e-04 - acc: 1.0000 - val_loss: 0.0051 - val_acc: 1.0000\n",
      "Epoch 194/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.1742e-04 - acc: 1.0000 - val_loss: 0.0051 - val_acc: 1.0000\n",
      "Epoch 195/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.1533e-04 - acc: 1.0000 - val_loss: 0.0050 - val_acc: 1.0000\n",
      "Epoch 196/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 1.1326e-04 - acc: 1.0000 - val_loss: 0.0050 - val_acc: 1.0000\n",
      "Epoch 197/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.1124e-04 - acc: 1.0000 - val_loss: 0.0050 - val_acc: 1.0000\n",
      "Epoch 198/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.0917e-04 - acc: 1.0000 - val_loss: 0.0049 - val_acc: 1.0000\n",
      "Epoch 199/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.0726e-04 - acc: 1.0000 - val_loss: 0.0048 - val_acc: 1.0000\n",
      "Epoch 200/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.0540e-04 - acc: 1.0000 - val_loss: 0.0048 - val_acc: 1.0000\n",
      "Epoch 201/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 1.0345e-04 - acc: 1.0000 - val_loss: 0.0048 - val_acc: 1.0000\n",
      "Epoch 202/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.0161e-04 - acc: 1.0000 - val_loss: 0.0047 - val_acc: 1.0000\n",
      "Epoch 203/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 9.9726e-05 - acc: 1.0000 - val_loss: 0.0047 - val_acc: 1.0000\n",
      "Epoch 204/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 9.7981e-05 - acc: 1.0000 - val_loss: 0.0046 - val_acc: 1.0000\n",
      "Epoch 205/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 9.6333e-05 - acc: 1.0000 - val_loss: 0.0046 - val_acc: 1.0000\n",
      "Epoch 206/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 9.4522e-05 - acc: 1.0000 - val_loss: 0.0046 - val_acc: 1.0000\n",
      "Epoch 207/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 9.2885e-05 - acc: 1.0000 - val_loss: 0.0045 - val_acc: 1.0000\n",
      "Epoch 208/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 9.1326e-05 - acc: 1.0000 - val_loss: 0.0045 - val_acc: 1.0000\n",
      "Epoch 209/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 8.9643e-05 - acc: 1.0000 - val_loss: 0.0045 - val_acc: 1.0000\n",
      "Epoch 210/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 8.8119e-05 - acc: 1.0000 - val_loss: 0.0044 - val_acc: 1.0000\n",
      "Epoch 211/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 8.6520e-05 - acc: 1.0000 - val_loss: 0.0044 - val_acc: 1.0000\n",
      "Epoch 212/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 8.5015e-05 - acc: 1.0000 - val_loss: 0.0043 - val_acc: 1.0000\n",
      "Epoch 213/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 8.3545e-05 - acc: 1.0000 - val_loss: 0.0043 - val_acc: 1.0000\n",
      "Epoch 214/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 8.2066e-05 - acc: 1.0000 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "Epoch 215/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 8.0641e-05 - acc: 1.0000 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "Epoch 216/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 7.9276e-05 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 217/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 7.7879e-05 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 218/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 7.6603e-05 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 219/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 7.5272e-05 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "Epoch 220/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 7.3963e-05 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "Epoch 221/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 7.2710e-05 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "Epoch 222/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 7.1450e-05 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "Epoch 223/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 7.0309e-05 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 224/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 6.9090e-05 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 225/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 6.7918e-05 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 226/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 6.6837e-05 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 227/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 6.5589e-05 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 228/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 6.4517e-05 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 229/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 6.3448e-05 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 230/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 6.2387e-05 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 231/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 6.1274e-05 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 232/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 6.0294e-05 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 233/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 5.9267e-05 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 234/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 5.8256e-05 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 235/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 5.7261e-05 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 236/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 5.6355e-05 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 237/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 5.5410e-05 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 238/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 5.4469e-05 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 239/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 5.3577e-05 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 240/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149/149 [==============================] - 0s 1ms/step - loss: 5.2675e-05 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 241/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 5.1810e-05 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 242/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 5.0959e-05 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 243/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 5.0133e-05 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 244/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 4.9288e-05 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 245/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 4.8513e-05 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 246/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 4.7652e-05 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 247/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 4.6927e-05 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 248/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 4.6093e-05 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 249/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 4.5364e-05 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 250/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 4.4610e-05 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 251/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 4.3939e-05 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 252/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 4.3162e-05 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 253/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 4.2488e-05 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 254/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 4.1807e-05 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 255/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 4.1129e-05 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 256/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 4.0430e-05 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 257/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 3.9799e-05 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 258/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 3.9128e-05 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 259/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 3.8538e-05 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 260/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 3.7898e-05 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 261/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 3.7269e-05 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 262/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 3.6689e-05 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 263/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 3.6111e-05 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 264/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 3.5526e-05 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 265/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 3.4978e-05 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 266/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 3.4417e-05 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 267/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 3.3834e-05 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 268/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 3.3332e-05 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 269/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 3.2782e-05 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 270/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 3.2267e-05 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 271/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 3.1736e-05 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 272/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 3.1228e-05 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 273/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 3.0731e-05 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 274/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 3.0238e-05 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 275/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 2.9751e-05 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 276/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 2.9277e-05 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 277/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 2.8812e-05 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 278/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 2.8357e-05 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 279/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 2.7883e-05 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 280/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 2.7466e-05 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 281/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 2.7018e-05 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 282/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 2.6597e-05 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 283/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 2.6191e-05 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 284/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 2.5749e-05 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 285/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 2.5337e-05 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 286/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 2.4948e-05 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 287/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 2.4558e-05 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 288/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 2.4165e-05 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 289/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 2.3804e-05 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 290/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 2.3415e-05 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 291/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 2.3061e-05 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 292/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 2.2695e-05 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 293/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 2.2341e-05 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 294/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 2.1988e-05 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 295/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 2.1648e-05 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 296/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 2.1313e-05 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 297/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 2.0974e-05 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 298/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 2.0665e-05 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 299/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149/149 [==============================] - 0s 1ms/step - loss: 2.0331e-05 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 300/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 2.0012e-05 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 301/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.9715e-05 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 302/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.9420e-05 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 303/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.9099e-05 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 304/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.8827e-05 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 305/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.8540e-05 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 306/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.8237e-05 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 307/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.7972e-05 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 308/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.7695e-05 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 309/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.7433e-05 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 310/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.7157e-05 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 311/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.6911e-05 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 312/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.6637e-05 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 313/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.6383e-05 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 314/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.6133e-05 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 315/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.5902e-05 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 316/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.5648e-05 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 317/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.5409e-05 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 318/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.5181e-05 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 319/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.4955e-05 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 320/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 1.4727e-05 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 321/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.4496e-05 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 322/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.4284e-05 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 323/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 1.4058e-05 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 324/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.3846e-05 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 325/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.3654e-05 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 326/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.3434e-05 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 327/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.3233e-05 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 328/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.3035e-05 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 329/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 1.2839e-05 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 330/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.2648e-05 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 331/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.2459e-05 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 332/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.2277e-05 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 333/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 1.2088e-05 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 334/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.1910e-05 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 335/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.1741e-05 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 336/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.1565e-05 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 337/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.1388e-05 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 338/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.1225e-05 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 339/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.1051e-05 - acc: 1.0000 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 340/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.0896e-05 - acc: 1.0000 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 341/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.0729e-05 - acc: 1.0000 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 342/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.0571e-05 - acc: 1.0000 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 343/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 1.0419e-05 - acc: 1.0000 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 344/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.0257e-05 - acc: 1.0000 - val_loss: 9.9490e-04 - val_acc: 1.0000\n",
      "Epoch 345/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 1.0116e-05 - acc: 1.0000 - val_loss: 9.9434e-04 - val_acc: 1.0000\n",
      "Epoch 346/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 9.9615e-06 - acc: 1.0000 - val_loss: 9.7763e-04 - val_acc: 1.0000\n",
      "Epoch 347/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 9.8093e-06 - acc: 1.0000 - val_loss: 9.6975e-04 - val_acc: 1.0000\n",
      "Epoch 348/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 9.6759e-06 - acc: 1.0000 - val_loss: 9.5781e-04 - val_acc: 1.0000\n",
      "Epoch 349/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 9.5253e-06 - acc: 1.0000 - val_loss: 9.5071e-04 - val_acc: 1.0000\n",
      "Epoch 350/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 9.3853e-06 - acc: 1.0000 - val_loss: 9.4268e-04 - val_acc: 1.0000\n",
      "Epoch 351/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 9.2455e-06 - acc: 1.0000 - val_loss: 9.3293e-04 - val_acc: 1.0000\n",
      "Epoch 352/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 9.1161e-06 - acc: 1.0000 - val_loss: 9.1902e-04 - val_acc: 1.0000\n",
      "Epoch 353/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 8.9835e-06 - acc: 1.0000 - val_loss: 9.1284e-04 - val_acc: 1.0000\n",
      "Epoch 354/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 8.8495e-06 - acc: 1.0000 - val_loss: 9.0246e-04 - val_acc: 1.0000\n",
      "Epoch 355/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 8.7204e-06 - acc: 1.0000 - val_loss: 8.9541e-04 - val_acc: 1.0000\n",
      "Epoch 356/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 8.5858e-06 - acc: 1.0000 - val_loss: 8.8643e-04 - val_acc: 1.0000\n",
      "Epoch 357/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149/149 [==============================] - 0s 2ms/step - loss: 8.4638e-06 - acc: 1.0000 - val_loss: 8.7823e-04 - val_acc: 1.0000\n",
      "Epoch 358/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 8.3397e-06 - acc: 1.0000 - val_loss: 8.6715e-04 - val_acc: 1.0000\n",
      "Epoch 359/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 8.2201e-06 - acc: 1.0000 - val_loss: 8.6061e-04 - val_acc: 1.0000\n",
      "Epoch 360/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 8.0969e-06 - acc: 1.0000 - val_loss: 8.5161e-04 - val_acc: 1.0000\n",
      "Epoch 361/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 7.9765e-06 - acc: 1.0000 - val_loss: 8.4290e-04 - val_acc: 1.0000\n",
      "Epoch 362/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 7.8643e-06 - acc: 1.0000 - val_loss: 8.4081e-04 - val_acc: 1.0000\n",
      "Epoch 363/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 7.7425e-06 - acc: 1.0000 - val_loss: 8.3254e-04 - val_acc: 1.0000\n",
      "Epoch 364/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 7.6326e-06 - acc: 1.0000 - val_loss: 8.2017e-04 - val_acc: 1.0000\n",
      "Epoch 365/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 7.5179e-06 - acc: 1.0000 - val_loss: 8.1367e-04 - val_acc: 1.0000\n",
      "Epoch 366/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 7.4140e-06 - acc: 1.0000 - val_loss: 8.0635e-04 - val_acc: 1.0000\n",
      "Epoch 367/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 7.3014e-06 - acc: 1.0000 - val_loss: 7.9884e-04 - val_acc: 1.0000\n",
      "Epoch 368/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 7.1949e-06 - acc: 1.0000 - val_loss: 7.9063e-04 - val_acc: 1.0000\n",
      "Epoch 369/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 7.0990e-06 - acc: 1.0000 - val_loss: 7.8014e-04 - val_acc: 1.0000\n",
      "Epoch 370/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 6.9897e-06 - acc: 1.0000 - val_loss: 7.7520e-04 - val_acc: 1.0000\n",
      "Epoch 371/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 6.8898e-06 - acc: 1.0000 - val_loss: 7.6980e-04 - val_acc: 1.0000\n",
      "Epoch 372/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 6.7925e-06 - acc: 1.0000 - val_loss: 7.6500e-04 - val_acc: 1.0000\n",
      "Epoch 373/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 6.6943e-06 - acc: 1.0000 - val_loss: 7.5841e-04 - val_acc: 1.0000\n",
      "Epoch 374/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 6.6029e-06 - acc: 1.0000 - val_loss: 7.4459e-04 - val_acc: 1.0000\n",
      "Epoch 375/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 6.4917e-06 - acc: 1.0000 - val_loss: 7.4213e-04 - val_acc: 1.0000\n",
      "Epoch 376/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 6.4097e-06 - acc: 1.0000 - val_loss: 7.3089e-04 - val_acc: 1.0000\n",
      "Epoch 377/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 6.3132e-06 - acc: 1.0000 - val_loss: 7.2915e-04 - val_acc: 1.0000\n",
      "Epoch 378/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 6.2233e-06 - acc: 1.0000 - val_loss: 7.1846e-04 - val_acc: 1.0000\n",
      "Epoch 379/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 6.1309e-06 - acc: 1.0000 - val_loss: 7.1332e-04 - val_acc: 1.0000\n",
      "Epoch 380/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 6.0394e-06 - acc: 1.0000 - val_loss: 7.0846e-04 - val_acc: 1.0000\n",
      "Epoch 381/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 5.9608e-06 - acc: 1.0000 - val_loss: 7.0087e-04 - val_acc: 1.0000\n",
      "Epoch 382/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 5.8728e-06 - acc: 1.0000 - val_loss: 6.9503e-04 - val_acc: 1.0000\n",
      "Epoch 383/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 5.7863e-06 - acc: 1.0000 - val_loss: 6.8778e-04 - val_acc: 1.0000\n",
      "Epoch 384/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 5.7012e-06 - acc: 1.0000 - val_loss: 6.8041e-04 - val_acc: 1.0000\n",
      "Epoch 385/500\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 5.6188e-06 - acc: 1.0000 - val_loss: 6.7795e-04 - val_acc: 1.0000\n",
      "Epoch 386/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 5.5382e-06 - acc: 1.0000 - val_loss: 6.7077e-04 - val_acc: 1.0000\n",
      "Epoch 387/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 5.4564e-06 - acc: 1.0000 - val_loss: 6.6599e-04 - val_acc: 1.0000\n",
      "Epoch 388/500\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 5.3852e-06 - acc: 1.0000 - val_loss: 6.5751e-04 - val_acc: 1.0000\n",
      "Epoch 389/500\n",
      "120/149 [=======================>......] - ETA: 0s - loss: 5.1482e-06 - acc: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-f320a55c3102>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m model.fit(x_train_scaled,y_train, \n\u001b[1;32m---> 11\u001b[1;33m validation_data = (x_val_scaled,y_val),epochs=500, batch_size=6)\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "model  = Sequential()\n",
    "model.add(Dense(6,input_dim = x_train_scaled.shape[1],activation=\"relu\"))\n",
    "model.add(Dense(6,activation=\"relu\"))\n",
    "model.add(Dense(1,activation = \"sigmoid\"))\n",
    "\n",
    "model.compile(optimizer = \"Adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(x_train_scaled,y_train, \n",
    "validation_data = (x_val_scaled,y_val),epochs=500, batch_size=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(model.history.history['loss'])\n",
    "plt.plot(model.history.history['val_loss'])\n",
    "plt.title(\"Model's Training & Validation loss across epochs\")\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history['acc'])\n",
    "plt.plot(model.history.history['val_acc'])\n",
    "plt.title(\"Model's Training & Validation Accuracy across epochs\")\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
