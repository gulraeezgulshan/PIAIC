{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HTTP in Python: The Requests Library\n",
    "\n",
    "Python ecosystem that can take care of HTTP for us. To name a few:\n",
    "\n",
    "* Python 3 comes with a built-in module called “urllib,” which can deal with all things HTTP (see https://docs.python.org/3/library/urllib.html).\n",
    "* “httplib2” (see https://github.com/httplib2/httplib2): a small, fast HTTP client library.\n",
    "* “urllib3” (see https://urllib3.readthedocs.io/): a powerful HTTP client for Python, used by the requests library below.\n",
    "* “requests” (see http://docs.python-requests.org/): an elegant and simple HTTP library for Python, built “for human beings.”\n",
    "* “grequests” (see https://pypi.python.org/pypi/grequests): which extends requests to deal with asynchronous, concurrent HTTP requests.\n",
    "* “aiohttp” (see http://aiohttp.readthedocs.io/): another library focusing on asynchronous HTTP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing/updating requests library\n",
    "pip install -U requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "url = 'http://www.webscrapingfordatascience.com/basichttp/'\n",
    "#url = 'http://www.google.com'\n",
    "r = requests.get(url)\n",
    "# r = requests.request('GET', url). #same as above\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(requests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r.status_code) # Which HTTP status code did we get back from the server?\n",
    "print(r.reason) # What is the textual status code?\n",
    "print(r.headers) # What were the HTTP response headers?\n",
    "print(r.request) # The request information is saved as a Python object in r.request:\n",
    "print(r.request.headers) # What were the HTTP request headers?\n",
    "print(r.text) # The HTTP response content:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Strings: URLs with Parameters\n",
    "\n",
    "##### URL parameters\n",
    "\n",
    "* http://www.webscrapingfordatascience.com/paramhttp/\n",
    "* http://www.webscrapingfordatascience.com/paramhttp/?query=test\n",
    "\n",
    "The optional “?…” part in URLs is called the “query string,”\n",
    "\n",
    "e.g\n",
    "\n",
    "* http://www.example.com/product_page.html?product_id=304\n",
    "* https://www.google.com/search?dcr=0&source=hp&q=test&oq=test\n",
    "* http://example.com/path/to/page/?type=animal&location=asia\n",
    "\n",
    "Web servers are smart pieces of software. When a server receives an HTTP request for such URLs, it may run a program that uses the parameters included in the query string — the “URL parameters” — to render different content. \n",
    "Compare \n",
    "* http://www.webscrapingfordatascience.com/paramhttp/?query=test \n",
    "* http://www.webscrapingfordatascience.com/paramhttp/?query=anothertest\n",
    "\n",
    "for instance. Evenfor this simple page, you see how the response dynamically incorporates the parameter data that you provided in the URL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query strings in URLs should adhere to the following conventions:\n",
    "* A query string comes at the end of a URL, starting with a single question mark, “?”.\n",
    "* Parameters are provided as key-value pairs and separated by an ampersand, “&”.\n",
    "* The key and value are separated using an equals sign, “=”. Since some characters cannot be part of a URL or have a special meaning (the characters “/”, “?”, “&”, and “=” for instance), URL “encoding” needs to be applied to properly format such characters when using them inside of a URL. Try this out using the URL http://www.webscrapingfordatascience.com/paramhttp/?query=another%20test%3F%26, which sends “another test?&” as the value for the “query” parameter to the server in an encoded form.\n",
    "* Other exact semantics are not standardized. In general, the order in which the URL parameters are specified is not taken into account by web servers, though some might. Many web servers will also be able to deal and use pages with URL parameters without a value, for example, http://www.example.com/?noparam=&anotherparam. Since the full URL is included in the request line of an HTTP request, the web server can decide how to parse and deal with these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### URL Rewriting\n",
    "\n",
    "* Most web servers will pay attention to parse URL on their end in order to use their information while rendering a page (or even ignore them when they’re unused — try the URL http://www.webscrapingfordatascience.com/paramhttp/query=test&other=ignored, for instance), but in recent years, the usage of URL parameters is being avoided somewhat. \n",
    "* Instead, most web frameworks will allow us to define “nice looking” URLs that just include the parameters in the path of a URL, for example, “/product/302/” instead of “products.html?p=302”. The former looks nicer when looking at the URL as a human, and search engine optimization (SEO) people will also tell you that search engines prefer such URLs as well. On the server-side of things, any incoming URL can hence be parsed at will, taking pieces from it and “rewriting” it, as it is called, so some parts might end up being used as input while preparing a reply. \n",
    "* For us web scrapers, this basically means that even although you don’t see a query string in a URL, there might still be dynamic parts in the URL to which the server might respond in different ways.\n",
    "\n",
    "\n",
    "#### URL Rewriting in Action\n",
    "\n",
    "* https://en.wikipedia.org/wiki/List_of_Game_of_Thrones_episodes\n",
    "* https://en.wikipedia.org/w/index.php?title=List_of_Game_of_Thrones_episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://www.webscrapingfordatascience.com/paramhttp/?query=test'\n",
    "r = requests.get(url)\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In some circumstances, requests will try to help you out and encode some characters for you:\n",
    "url = 'http://www.webscrapingfordatascience.com/paramhttp/?query=a query with spaces'\n",
    "r = requests.get(url)\n",
    "print(r.request.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# However, sometimes the URL is too ambiguous for requests to make sense of it:\n",
    "url = 'http://www.webscrapingfordatascience.com/paramhttp/?query=complex?&'\n",
    "r = requests.get(url)\n",
    "print(r.request.url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, requests is unsure whether you meant “?&” to belong to the actual URL as is or whether you wanted to encode it. Hence, requests will do nothing and just request the URL as is. On the server-side, this particular web server is able to derive that the second question mark (“?”) should be part of the URL parameter (and should have been properly encoded, but it won’t complain), though the ampersand “&” is too ambiguous in this case. Here, the web server assumes that it is a normal separator and not part of the URL parameter value.\n",
    "\n",
    "###### So how then, can we properly resolve this issue?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import quote, quote_plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_string = 'a query with /, spaces and?&'\n",
    "print(quote(raw_string))\n",
    "print(quote_plus(raw_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://www.webscrapingfordatascience.com/paramhttp/?query='\n",
    "\n",
    "print('\\nUsing quote:')\n",
    "# Nothing is safe, not even '/' characters, so encode everything\n",
    "r = requests.get(url + quote(raw_string, safe=''))\n",
    "print(r.url)\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nUsing quote_plus:')\n",
    "r = requests.get(url + quote_plus(raw_string))\n",
    "print(r.url)\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://www.webscrapingfordatascience.com/paramhttp/'\n",
    "\n",
    "parameters = {\n",
    "    'query': 'a query with /, spaces and?&'\n",
    "}\n",
    "\n",
    "r = requests.get(url, params=parameters)\n",
    "print(r.url)\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Empty parameters, for example, as in “params={’query’: ”}” will end up in the URL with an equals sign included\n",
    "\n",
    "url = 'http://www.webscrapingfordatascience.com/paramhttp/'\n",
    "\n",
    "parameters = {\n",
    "    'query':''\n",
    "}\n",
    "\n",
    "r = requests.get(url, params=parameters)\n",
    "print(r.url)\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/w/index.php/?title=List_of_Game_of_Thrones_episodes&oldid=802553687'\n",
    "r = requests.get(url)\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the response body captured by r.text now spits out a slew of confusing-looking text. This is HTML-formatted text, and although the content we’re looking for is buried somewhere inside this soup, we’ll need to learn about a proper way to get out the information we want from there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Fragment Identifier\n",
    "\n",
    "* http://www.example.org/about.htm?p=8#contact\n",
    "\n",
    "The fragmentidentifier, or “hash,” as it is sometimes called. It is prepended by a hash mark (“#”) and comes at the very end of a URL, even after the query string, for instance, as in .This part of the URL is meant to identify a portion of the document corresponding to the URL. \n",
    "\n",
    "For instance, a web page can include a link including a fragment identifier that, if you click on it, immediately scrolls your view to the corresponding part of the page. However, the fragment identifier functions differently than the rest of the URL, as it is processed exclusively by the web browser with no participation at all from the web server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
